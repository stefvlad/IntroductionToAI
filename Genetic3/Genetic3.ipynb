{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0smoWI3Zo4xd"
      },
      "source": [
        "---\n",
        "\n",
        "# **1. Init**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "id": "MhhuN9SK3Uq3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "id": "QTP7L2-maaR4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "id": "sr8wp7To7IaN"
      },
      "outputs": [],
      "source": [
        "def generate_random_binary_string(length):\n",
        "  binary_string = \"\"\n",
        "\n",
        "  for i in range(length):\n",
        "    binary_string += str(random.randint(0,1))\n",
        "\n",
        "  return binary_string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Mz2M2bO75i8"
      },
      "source": [
        "---\n",
        "\n",
        "# **2. Generating very first population**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "id": "HKPGY0Hp3o7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e597ee0-771e-40a6-986f-2699d27114d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['111010', '110110', '100011', '001100', '010111', '100101']\n",
            "[58, 54, 35, 12, 23, 37]\n",
            "{58: '111010', 54: '110110', 35: '100011', 12: '001100', 23: '010111', 37: '100101'}\n"
          ]
        }
      ],
      "source": [
        "chromosome_length = 6\n",
        "\n",
        "map = {}\n",
        "\n",
        "first_population_integers = []\n",
        "first_population_strings = []\n",
        "\n",
        "for i in range(6):\n",
        "  first_population_strings.append(generate_random_binary_string(chromosome_length))\n",
        "  first_population_integers.append(int(first_population_strings[i], 2))\n",
        "\n",
        "for i in range(6):\n",
        "  map[first_population_integers[i]] = first_population_strings[i]\n",
        "\n",
        "print(first_population_strings)\n",
        "print(first_population_integers)\n",
        "print(map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIHIrN_IajeF"
      },
      "source": [
        "---\n",
        "\n",
        "# **3. Models configuration**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "id": "b-1BI26we-TC"
      },
      "outputs": [],
      "source": [
        "model_1 = models.Sequential()\n",
        "\n",
        "if first_population_integers[0] != 0:\n",
        "  model_1.add(layers.Dense(first_population_integers[0], activation='relu', name='hidden', input_dim=64))\n",
        "  model_1.add(layers.Dense(10, activation='softmax', name='output'))\n",
        "else:\n",
        "  model_1.add(layers.Dense(10, activation='softmax', name='output', input_dim=64))\n",
        "\n",
        "# for multi-class classification problem\n",
        "model_1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "id": "cHSC-IFyfbTh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b46873f0-220f-452c-943d-949f4756a6a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_168\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden (Dense)              (None, 58)                3770      \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                590       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,360\n",
            "Trainable params: 4,360\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_1.summary() # hidden 128 * 64 + 128 biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "id": "-kwOtwPBrsKw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "b2722ff6-91cd-4998-9c59-c36440d4fe69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcUAAAEnCAYAAADYTVgNAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzdeVgUZ7Y/8G9BA90N3YCKQEAIi0vcYowmgvpT41wT5bogKETNjGZiwJgQFB1E3IJiQjDq40JyXcLMaEYRzKBRMffqjHEclzGjRoOJC4qAiCyy78L5/WHTY9uA3dAbcD7P039Y9VbVqTpNH7u63vcViIjAGGOMMZgZOwDGGGPMVHBRZIwxxhS4KDLGGGMKXBQZY4wxBVFLK2bMmGHIOBhjjDGDWbx4MXx8fNSWt/hNMSUlBTk5OXoNipmW8+fP4/z588YOo0PJyclBSkqKscNgesB/D51XSkoKsrOzm13X4jdFAFi0aBFmzpypl6CY6Wm6O5CcnGzkSDqOAwcOICgoiK9ZJ8R/D52XIAgtruPfFBljjDEFLoqMMcaYAhdFxhhjTIGLImOMMabARZExxhhT0ElRnDdvHsRiMQRBQE1NTattjx07BltbW3z33Xcttnnvvfcgk8kgCAKuXLnS7nb6psk5dSV8PRhjHZVOimJiYiKWLFmiUVtNJuXYtWsXdu7cqbN2+sYTjaji68EY66ha7aeoD35+figtLTX0YfXKlM6puroa48ePx9mzZ40WA18PxlhHpfPfFFvrFKmP/ejqeJ3F7t27kZ+fb+wwTAZfD8aYNnRaFM3MzHD06FFMnDgRtra2cHZ2xtdff61cf+bMGbi5uUEQBGzbtk25nIgQHx+Pvn37wsrKCra2tli6dKna/jVt19DQgFWrVsHNzQ0SiQSDBw9GUlISACAhIQHW1taQSqU4dOgQJk6cCLlcDldXV+zbt0/rc27unDQ9xpYtWyAWi9GzZ0+EhobC2dkZYrEYvr6+uHDhgrJdWFgYLC0t4eTkpFy2cOFCWFtbQxAEFBYWAgDCw8MRERGBjIwMCIIAb29vrc+nvTrC9Th+/DjkcjliY2MNcUkYYx0JtQAAJSUltbRaTXR0NAGgkydPUklJCT169IgmTZpEVlZWVFlZqWyXnZ1NAGjr1q0q2wqCQF988QUVFxdTVVUVbd++nQDQ5cuXtW63ZMkSsrKyopSUFCouLqbly5eTmZkZXbx4US3W0tJSys/Pp9GjR5O1tTXV1dVpfM7POydNjhESEkLW1tZ0/fp1qqmpofT0dBo+fDjJZDLKyspStps9ezY5OjqqHDc+Pp4AUEFBgXJZQEAAeXl5aX0ORESBgYEUGBjYpm2fZurX48iRIySTySgmJqbd55qUlESt/BmxDkxXfw/M9LRW33R++9TX1xe2trawt7dHcHAwamtrcffu3RbbV1dXY9OmTfjNb36DxYsXw87ODhKJBN26dWtTu5qaGiQkJMDf3x8BAQGws7PDihUrYGFhgcTERLVY5XI5HBwcEBwcjMrKSmRlZenuYmh4DJFIhJdeeglWVlbo378/EhISUF5erhZvZ2AK18PPzw9lZWVYuXKlTvbHGOs89NpP0cLCAgBQX1/fYpvbt2+jqqoK48ePb3Vfmra7ceMGqqqqMHDgQOUyiUQCJycn/Prrry1uZ2lp+dxY20vTYwwbNgxSqbTVeDsDvh6MMVNj9M77TdNTOTg46KRdZWUlAGDFihUQBEH5unfvHqqqqnQQsWFYWVmhoKDA2GGYDL4ejDFDMHpRFIvFAIDa2lqdtGsqmps2bQIRqbzOnTung4j1r76+HiUlJXB1dTV2KCaBrwdjzFCMXhQHDhwIMzMz/PDDDzpp16tXL4jFYqOOcNNep06dAhFhxIgRymUikUivt3ZNGV8PxpihGL0oOjg4ICAgACkpKdi9ezfKyspw9epV7Nixo03txGIx5s2bh3379iEhIQFlZWVoaGhATk4OHjx4YMhT01hjYyOKi4vx+PFjXL16FeHh4XBzc8PcuXOVbby9vfHo0SOkpqaivr4eBQUFuHfvntq+unXrhtzcXGRmZqK8vLxDFg59X4+0tDTuksEYa15bHll9VlxcHEkkEgJAvXv3poyMDNq7dy/Z29sTAHJ1daWff/6Ztm7dSk5OTgSApFIpTZkyhYiIysvL6b333qPu3buTjY0NjRo1ilatWqXc9qefftKqXW1tLUVGRpKbmxuJRCJycHCggIAASk9Pp+3bt5NUKlWJdceOHSSXywkAubu7082bNzV8sJeaPSdtjhESEkIWFhbk4uJCIpGI5HI5TZs2jTIyMlSOU1RUROPGjSOxWEweHh700Ucf0dKlSwkAeXt7K7srXLp0idzd3UkikdCoUaMoLy9P43PRxSPoHeF6HDt2jGQyGa1bt65d50rEXTI6M+6S0Xm1Vt8ERQM1giAgKSkJM2fO1G9V7uJCQ0ORnJyMoqIiY4eCGTNmAACSk5ONFoMpXQ9NHDhwAEFBQTzeaydkCn8PTD9aq29Gv33KnozAw/6DrwdjzFi4KDbj119/VenO0dIrODjY2KEyxhjTIS6KzejXr59ad47mXvv372/XcZYvX47ExESUlpbCw8MDKSkpOjqDjqmrXI/Q0FCV/1zNmTNHrc2JEycQFRWFgwcPwtPTU9n2nXfeUWs7YcIEyGQymJubY8CAAbh06ZIhTqNd6uvrsX79enh7e8PS0hJ2dnYYOHAgMjMzW9ympqYG/fr1w4oVK5TLDh8+jLi4OLW7C6mpqSrXuEePHvo6FRWc206Q27b8EMk6J36wQHttedAmJCSEunXrRmlpaXTjxg2qqalRWb9q1SqaPHkylZWVKZd5eXlR9+7dCQAdOXJEbZ9paWk0derUtp2EEfj7+1Pfvn3p/PnzVF9fT7m5uTRlyhS6du1ai9ssXryYAFB0dLTK8s2bN9OYMWOouLhYuayxsZFycnLo9OnTNGnSJOrevbvWMbbl74Fz2zFy21p942+KjBmBRCLBW2+9hT59+sDKykq5/LPPPsP+/ftx4MAByGQylW22bNkCMzMzhISEmMx8lW2xf/9+pKamIjk5Ga+//jpEIhGcnZ1x6NAhleEZn3b27Fn8/PPPza77+OOP8fLLL2PSpEl4/PgxgCcPUri4uGD06NHo3bu33s6lOZzbjp1bLoqMmYjbt29j5cqV+OSTT5QjOD3N19cX4eHhuH//PpYsWWKECHXjyy+/xNChQzFo0CCN2ldXV2Pp0qXYvHlzi23WrFmDK1eutNrGmDi3zTPF3HJRZMxEbNmyBUSEKVOmtNhm3bp16NOnD3bt2oUTJ060uj8iwsaNG5Uzjtjb22PatGkqA6trM79oa/OUaqqurg7nz5/HkCFDNN4mOjoaCxcubHXcY3t7e4wZMwabN282ye4xnNvmmWJuuSgyZiKOHj2Kvn37QiqVtthGIpHgj3/8I8zMzDB//nzlAPjNWbNmDaKiohAdHY38/HycPn0a2dnZGD16NB4+fAgA+OCDD7Bo0SJUV1dDJpMhKSkJGRkZ8PT0xPz581VGRFq2bBk+//xzbNq0CQ8ePMDkyZMxa9Ys/PjjjxqfY25uLurq6vDvf/8b48aNU04k/dJLL2H79u1qH3r//Oc/kZGRgVmzZj1336+88gru37+Pn376SeN4DIVz23Fyy0WRMRNQWVmJu3fvwsvL67ltfXx8sGjRImRmZmLZsmXNtqmursbGjRsxffp0zJkzB7a2thg0aBC++uorFBYWqg2PCLQ+16U285S2pqKiAsCTYRtjY2ORnp6Ohw8fYtq0afjwww/xl7/8ReUcwsPDkZCQoNG+m35funbtmsbxGALntmPlttWiGBQUpFF/PX51jldKSgpSUlKMHkdHegUFBenkDzE/Px9E1Oo3iaetW7cOffv2xfbt23HmzBm19enp6aioqMCwYcNUlg8fPhyWlpa4cOFCq/t/dq7Lts5T+qymB08GDBgAX19fdOvWDba2tvjkk09ga2ur8oG+fPlyvP/++3BxcdFo303Xrumbkqng3Has3IpaWxkeHg4fHx+9B8FMw6ZNmwAAixYtMnIkHce5c+d08gBATU0NAKg8rdgasViMxMREjBo1Cu+++y7i4uJU1peUlAAAbGxs1La1s7NDeXm5VvE9PU/p033JAMDZ2Vnj/TS1LSwsVFluaWkJd3d3ZGRkAADOnDmDa9euYePGjRrvWyKRAPjPtTQVnNuOldtWi6KPjw+PfdqFNI3xyDnXji6KYtMfvTZD3Pn4+GDx4sXYsGED1q5dCzc3N+U6Ozs7AGj2A7Itc1M+PU9peHi4Vts+zcbGBr1798b169fV1j1+/Bi2trYAgN27d+PkyZMwM1O/mRUbG4vY2FhcvHhR5dtSXV0dgP9cS1PBue1YueXfFBkzAT179oQgCFr3UVu7di369euHy5cvqywfOHAgbGxs1B6UuHDhAurq6vDqq69qdRxdzlMaFBSEy5cv486dO8plVVVVuHfvnvJR/sTERLURpAoKCgA8eWKRiNRuHzZdO0dHx3bHqEuc246VWy6KjJkAqVQKT09P5OTkaLVd0602c3NzteURERH49ttvsXfvXpSVleHatWtYsGABnJ2dERISovVxnjdPaXBwMBwdHZ87FNnixYvh7u6OuXPnIisrC0VFRYiMjER1dXWLD5doounaadpHzlA4tx0rt1wUGTMRfn5+SE9PR3V1tXLZX//6V3h7eyMjIwPDhw/HRx99pLbdiBEjsHjxYrXlq1evxvr16xETE4MePXpgzJgxePHFF3Hq1ClYW1sDeNKXrem35MGDB+POnTvYuXMnIiIiAABvvfUWbt26BeDJbeJFixYhLi4O3bt3h7OzM8LDw1FcXAzgyS2u/Px8HDp0qNXztLe3xz/+8Q+4urpiyJAhcHFxwb/+9S8cPXpUqz5uz7p48SJcXFwwePDgNu9DXzi3HSi3bRkbjnVOPPap9to69qmLi4va8lu3bpFIJKI9e/boKjyDamhooNGjR9Pu3bsNfuzCwkISi8W0YcMGtXUff/yxQcc+5dzqlj5y21p942+KjBlBdXU1vv/+e9y6dUv5EIG3tzdiYmIQExOj7PPVUTQ0NCA1NRXl5eVGmVJtzZo1GDJkCMLCwgA8GfElNzcXZ86cwe3btw0aC+dWtwydW4MWxfPnz+Oll16CmZkZBEGAo6Mj1q1bZ8gQnuvZ6VycnJyanf6FsfZ49OiRctDod999V7k8KioKM2bMQHBwcIcaGPrUqVM4ePAg0tLSNO6PpysbN27ElStXcOzYMVhYWAAADh06pBw0+ujRowaNh3OrO0bJbVu+XrbXm2++SQBUpgMxNV5eXmRra2vsMAyKb59qry23TzXx/fffU2RkpM7329mkpqbS+vXr6fHjxzrft77+Hji3mtFnblurb13+9ml1dTV8fX2NHQZTMEQ+OkLOJ0yYgM8++8zYYZi8qVOnIioqSu0JTVPGudWMsXLb5Yvi7t27kZ+fb+wwmIIh8sE5Z4y1xCSKoqZTnGzZsgVisRg9e/ZEaGiochR2X19flfH+wsLCYGlpCScnJ+WyhQsXwtraGoIgKIchCg8PR0REBDIyMiAIAry9vdsU/z/+8Q/0798ftra2EIvFGDRoEL7//nsAwHvvvaf8fdLLy0vZEXfevHmQSqWwtbXF4cOHAbQ+fcvnn38OqVQKmUyG/Px8REREwMXFBTdu3GhTzLpCGkxh0558GCrnx48fh1wuR2xsrF6vF2PMxLXlnmt7NfebYnR0NAGgkydPUmlpKeXn59Po0aPJ2tqa6urqlO1CQkLI2tqarl+/TjU1NZSenk7Dhw8nmUxGWVlZynazZ88mR0dHlePGx8cTACooKFAuCwgIIC8vL7UYtflNMTk5mdasWUOPHj2ioqIiGjFihMpjwgEBAWRubk73799X2W7WrFl0+PBh5b+XLFlCVlZWlJKSQsXFxbR8+XIyMzOjixcvqlyjjz/+mLZu3UrTp0+nX375RaMYNdGW31BWrVpFlpaWtGfPHiopKaGrV6/S0KFDqUePHpSXl6ds1558GCLnR44cIZlMRjExMVqdv75+U2TGx7+xd16t1TeT+Kb4tNamOGkiEomU30z69++PhIQElJeXazXNiS4FBgZi9erVsLe3R7du3TBlyhQUFRUphy5asGABGhoaVOIrKyvDxYsXMWnSJADaTd/y2Wef4cMPP8TBgwfRr18/w53oM9oyhU1b6Tvnfn5+KCsrw8qVK3WyP8ZYx2RyRfFpz05x0pJhw4ZBKpVqNc2JPjU9Otw0APAbb7yBPn364Ouvv1ZOtLl//34EBwcrf0TW1fQthtTeKWzaw9RyzhjrHEy6KGrDyspK+c3M0I4ePYqxY8fCwcEBVlZW+MMf/qCyXhAEhIaG4s6dOzh58iQA4M9//jN+//vfK9s8PX3L0/P13bt3D1VVVYY7GS3oegobbRkz54yxzqlTFMX6+vo2TZnSVqdPn1aOKZiVlQV/f384OTnhwoULKC0tVZv/DADmzp0LsViMXbt24caNG5DL5XB3d1euf3r6FnpmBPlz584Z5Ly0pespbLRh6JwzxrqGVudT7ChOnToFIsKIESOUy0Qi0XNvu7bVv//9b+Wgu9euXUN9fT0++OADeHp6AnjyzfBZ9vb2CAoKwv79+yGTyTB//nyV9bqcvsVQtJnCRtf5MHTOGWNdQ4f8ptjY2Iji4mI8fvwYV69eRXh4ONzc3DB37lxlG29vbzx69Aipqamor69HQUEB7t27p7avbt26ITc3F5mZmSgvL2/1Q7W+vh4PHz5UGYm+afLPEydOoKamBrdu3Wrxt7QFCxagtrYWR44cweTJk1XWaTJ9i6nRZgqb9uZD3zlPS0vjLhmMMcN2yTh//jwNGDCAzMzMCAA5OTlRbGwsbd++naRSKQGg3r17U0ZGBu3YsYPkcjkBIHd3d7p58yYRPXk838LCglxcXEgkEpFcLqdp06ZRRkaGyrGKiopo3LhxJBaLycPDgz766CNaunQpASBvb2/lo/yXLl0id3d3kkgkNGrUKPryyy/Jy8uLALT6+vbbb5XHioyMpG7dupGdnR3NmDGDtm3bRgDIy8tLpcsAEdErr7xCUVFRzV6f2tpaioyMJDc3NxKJROTg4EABAQGUnp5OcXFxJJFICAD16tVLL6Ptt+UR9MbGRoqPj6fevXuThYUF2dvbk7+/P924cUOlXVvzkZeXp/ec5+Xl0bFjx0gmk9G6deu0On/uktF5cZeMzqu1+iYoGqgRBAFJSUmYOXOmXouytkJDQ5GcnIyioiJjh9Imfn5+2LZtGzw8PIwdipoZM2YAAJKTk40ciSpTzvmBAwcQFBSEFv6MWAdmqn8PrP1aq28d8vZpU1eHjuDp27FXr16FWCw2yYJo6jpSzhljHVeneNDGlEVGRmLBggUgIsybNw979uwxdkiMMcZa0KG+KS5fvhyJiYkoLS2Fh4cHUlJSjB3Sc0mlUvTr1w+/+c1vsGbNGvTv39/YIXUoHTHnjLGOq0MVxfXr16O2thZEhLt37yIwMNDYIT3XunXr0NDQgKysLLUnTtnzdcScM8Y6rg5VFBljjDF94qLIGGOMKXBRZIwxxhS4KDLGGGMKrXbJMNWBqJl+5OTkAHjSIZ1ppulvhK9Z58N/D11TqyPaMMYYY51RSyPatPhNkYetYsxwTHVYRca6Gv5NkTHGGFPgosgYY4wpcFFkjDHGFLgoMsYYYwpcFBljjDEFLoqMMcaYAhdFxhhjTIGLImOMMabARZExxhhT4KLIGGOMKXBRZIwxxhS4KDLGGGMKXBQZY4wxBS6KjDHGmAIXRcYYY0yBiyJjjDGmwEWRMcYYU+CiyBhjjClwUWSMMcYUuCgyxhhjClwUGWOMMQUuiowxxpgCF0XGGGNMgYsiY4wxpsBFkTHGGFPgosgYY4wpcFFkjDHGFLgoMsYYYwpcFBljjDEFLoqMMcaYAhdFxhhjTIGLImOMMabARZExxhhTEIiIjB0EY11JSEgIbty4obLs0qVL8PDwgL29vXKZubk5/vSnP8HV1dXQITLWZYmMHQBjXY2joyN27Nihtvzq1asq//b09OSCyJiB8e1Txgxs1qxZz21jaWmJuXPn6j8YxpgKvn3KmBEMHDgQ169fR2t/fjdu3ECfPn0MGBVjjL8pMmYEv/3tb2Fubt7sOkEQ8PLLL3NBZMwIuCgyZgRvv/02Ghoaml1nbm6O3/3udwaOiDEG8O1TxozG19cXFy5cQGNjo8pyQRCQnZ0NFxcXI0XGWNfF3xQZM5J33nkHgiCoLDMzM8OoUaO4IDJmJFwUGTOSGTNmqC0TBAG//e1vjRANYwzgosiY0fTo0QPjx49XeeBGEAT4+/sbMSrGujYuiowZ0Zw5c5TdMszNzfHmm2+ie/fuRo6Ksa6LiyJjRjR9+nRYWloCAIgIc+bMMXJEjHVtXBQZMyJra2v893//N4Ano9hMnjzZyBEx1rVxUWTMyGbPng0A8Pf3h7W1tZGjYaxr03k/xQMHDiAoKEiXu2SMMcbUBAYGIjk5Waf71NssGUlJSfraNTOic+fOYfPmzZxfLQUFBSE8PBw+Pj7Nrt+7dy+Cg4MhEvHENcbE7++OY9OmTXrZr97+AmfOnKmvXTMj27x5M+dXS0FBQfDx8Wnxuk2ZMgVisdjAUbHm8Pu7Y9D1N8Qm/JsiYyaACyJjpoGLImOMMabARZExxhhT4KLIGGOMKXBRZIwxxhQ6dVGcN28exGIxBEFATU1Nq22PHTsGW1tbfPfddy22ee+99yCTySAIAq5cudLudl2ZJtebMcYMrVMXxcTERCxZskSjtpqMYbBr1y7s3LlTZ+26Mp7bmjFmirinsIKfnx9KS0uNHUaXYUrXu7q6GuPHj8fZs2eNHQpjzMg69TfFpz07w7m+96Or4zH92717N/Lz840dBmPMBHSJomhmZoajR49i4sSJsLW1hbOzM77++mvl+jNnzsDNzQ2CIGDbtm3K5USE+Ph49O3bF1ZWVrC1tcXSpUvV9q9pu4aGBqxatQpubm6QSCQYPHiwcjiphIQEWFtbQyqV4tChQ5g4cSLkcjlcXV2xb98+PVwV42nuemt6/lu2bIFYLEbPnj0RGhoKZ2dniMVi+Pr64sKFC8p2YWFhsLS0hJOTk3LZwoULYW1tDUEQUFhYCAAIDw9HREQEMjIyIAgCvL29AQDHjx+HXC5HbGysIS4JY8xUkI4lJSWRHnbbZtHR0QSATp48SSUlJfTo0SOaNGkSWVlZUWVlpbJddnY2AaCtW7eqbCsIAn3xxRdUXFxMVVVVtH37dgJAly9f1rrdkiVLyMrKilJSUqi4uJiWL19OZmZmdPHiRbVYS0tLKT8/n0aPHk3W1tZUV1dngKv1fLrKb0vXW5PzDwkJIWtra7p+/TrV1NRQeno6DR8+nGQyGWVlZSnbzZ49mxwdHVWOGx8fTwCooKBAuSwgIIC8vLxU2h05coRkMhnFxMS0+1yJiABQUlKSTvbF9MfUPr9YywIDAykwMFDn++0S3xQBwNfXF7a2trC3t0dwcDBqa2tx9+7dFttXV1dj06ZN+M1vfoPFixfDzs4OEokE3bp1a1O7mpoaJCQkwN/fHwEBAbCzs8OKFStgYWGBxMREtVjlcjkcHBwQHByMyspKZGVl6e5imDhNzl8kEuGll16ClZUV+vfvj4SEBJSXl6tdy7by8/NDWVkZVq5cqZP9McY6hi5TFJ9mYWEBAKivr2+xze3bt1FVVYXx48e3ui9N2924cQNVVVUYOHCgcplEIoGTkxN+/fXXFrdrmpW9tVg7M03Pf9iwYZBKpa1eS8YYe54uWRQ1kZOTAwBwcHDQSbvKykoAwIoVKyAIgvJ17949VFVV6SBiZmVlhYKCAmOHwRjrwLgotqBp1oLa2lqdtGsqmps2bQIRqbzOnTung4i7tvr6epSUlMDV1dXYoTDGOjAuii0YOHAgzMzM8MMPP+ikXa9evSAWi3mEGz05deoUiAgjRoxQLhOJRF32tjNjrG24KLbAwcEBAQEBSElJwe7du1FWVoarV69ix44dbWonFosxb9487Nu3DwkJCSgrK0NDQwNycnLw4MEDQ55ap9DY2Iji4mI8fvwYV69eRXh4ONzc3DB37lxlG29vbzx69Aipqamor69HQUEB7t27p7avbt26ITc3F5mZmSgvL0d9fT3S0tK4SwZjXZGuH2c1pUea4+LiSCKREADq3bs3ZWRk0N69e8ne3p4AkKurK/3888+0detWcnJyIgAklUppypQpRERUXl5O7733HnXv3p1sbGxo1KhRtGrVKuW2P/30k1btamtrKTIyktzc3EgkEpGDgwMFBARQeno6bd++naRSqUqsO3bsILlcTgDI3d2dbt68abRr2UQX+W3uemtz/iEhIWRhYUEuLi4kEolILpfTtGnTKCMjQ+U4RUVFNG7cOBKLxeTh4UEfffQRLV26lACQt7e3svvGpUuXyN3dnSQSCY0aNYry8vLo2LFjJJPJaN26de061ybgLhkdgil9frHW6atLhkCk20EoDxw4gKCgIB7bspMyhfyGhoYiOTkZRUVFRotBW4IgICkpCTNnzjR2KKwVpvD+ZpqZMWMGACA5OVmn++Xbp6xDamhoMHYIjLFOiIsiYybuxIkTiIqKwsGDB+Hp6anszvPOO++otZ0wYQJkMhnMzc0xYMAAXLp0yQgRa6e+vh7r16+Ht7c3LC0tYWdnh4EDByIzM7PFbWpqatCvXz+sWLFCuezw4cOIi4sz6n+YOnOu1q1bp9KdrOn1dN/rJn/5y18wfPhwyGQyuLu7Y968ecjLy1OuN4VctYSLIutQli9fjsTERJSWlsLDwwMpKSnGDkmvVq9ejS1btmD58uUICAjAnTt34OXlhe7du2Pv3r04evSoSvv//d//RXJyMiZPnoz09HQMHTrUSJFrLigoCH/+85/xzTffoKqqCr/88gu8vLxQUVHR4jbR0dG4ceOGyrIpU6ZALBZj/PjxKCkp0XfYarpCrjSRlJSE2bNnY8aMGcjJycGhQ4dw+vRpTJw4EY8fPwZg/Fy1hosi61DWrzzxBKkAACAASURBVF+P2tpaEBHu3r2LwMBAY4ekN5999hn279+PAwcOQCaTqazbsmULzMzMEBISYjJTcLXF/v37kZqaiuTkZLz++usQiURwdnbGoUOHmv0GAgBnz57Fzz//3Oy6jz/+GC+//DImTZqk/AA2hK6QKwDYs2ePWj/rZ3PxP//zP3jhhRewdOlS2NraYsiQIVi8eDGuXLmiMmi/sXL1PFwUGTNBt2/fxsqVK/HJJ58oB4h4mq+vL8LDw3H//n2NJ9I2RV9++SWGDh2KQYMGadS+uroaS5cuxebNm1tss2bNGly5cqXVNrrUVXKlqezsbDg7O6tMn9erVy8AUOsSZehcaYKLImMmaMuWLSAiTJkypcU269atQ58+fbBr1y6cOHGi1f0RETZu3KgcRN3e3h7Tpk1TGStWm+nLWpsGTVN1dXU4f/48hgwZovE20dHRWLhwYavDKtrb22PMmDHYvHmzQZ4i7Qq50oanp6fa/KRNvyd6enqqLDd0rjSi6z4e3M+nc+P8tg207Kfo6elJ/fv3b3adl5cX3b17l4iIzp49S2ZmZvTiiy9SRUUFERGlpaXR1KlTVbZZtWoVWVpa0p49e6ikpISuXr1KQ4cOpR49elBeXp6ynabTdz1vGjRN3L17lwDQkCFDaOzYseTk5ERWVlbUr18/2rZtGzU2Nqq0P3PmjLIPcUFBAQGg6OjoZvcdFRWlNnWbJtry/u4KuSIiWrt2Lbm6upKdnR1ZWFjQiy++SFOnTqV//etfKu1OnTpFFhYWtGXLFiorK6Off/6ZXnrpJXrzzTeb3W9bc6WvfopcFJlWOL9to01RrKioIEEQaPLkyc2uf/qDlogoIiKCANCHH35IROoftFVVVWRjY0PBwcEq+/nXv/5FAFTmjGz6oK2urlYua5ob9Pbt20REVF1dTVKpVGV/VVVVZGVlRR988IFG50hEdO3aNQJA//Vf/0X//Oc/qaioiEpKSmjZsmUEgPbu3auy/2HDhlFOTg4RPb8ofv311wSA/vznP2scD5H27++ukisioqysLLp06RKVl5dTbW0tnTt3jl555RWSSCT0888/q7RdsWIFAVC+XF1dKTs7u9n9tjVX+iqKIn19Az1w4IC+ds2MqGnwcs6v/uTn54OIIJVKNWq/bt06HDlyBNu3b0dQUJDa+vT0dFRUVGDYsGEqy4cPHw5LS0uVhx+a8+z0XW2dBu1ZVlZWAIABAwbA19dXufyTTz7Bl19+iR07dmD27NkAnjx1/P7778PFxUWjfTddu4cPH2ocT1t0lVwBT34XbPptEABGjBiBxMREDBkyBNu3b0dCQgKAJ7e4d+3ahZMnT+L1119Hfn4+li1bBh8fH5w9e1ZlH4DhcqUpvRXF5hLOOg/Or/7U1NQA+E/ReB6xWIzExESMGjUK7777LuLi4lTWNz3ybmNjo7atnZ0dysvLtYrv6WnQnu4nCADOzs4a76epbWFhocpyS0tLuLu7IyMjAwBw5swZXLt2DRs3btR43xKJBMB/rqW+dJVctWTQoEEwNzfHzZs3AQAPHjxAXFwcoqKi8MYbbwAAPDw8sHPnTtjb2yM+Ph5btmxR2YehcqUpvT1oQ888ttvVX8CT/jvGjqO9r6Yf6I0dR0d7aaPpQ0Kbjs0+Pj5YvHgxbt26hbVr16qss7OzA4BmP1DbMt2WrqZBs7GxQe/evXH9+nW1dY8fP4atrS0AYPfu3Th58iTMzMyUHcabYoiNjYUgCPjxxx9Vtq+rqwPwn2upL10lVy1pbGxEY2Oj8j8Ft27dQkNDA1544QWVdnK5HN26dUN6erraPgyVK03x06eMmZiePXtCEASt+7StXbsW/fr1w+XLl1WWDxw4EDY2NmqF48KFC6irq8Orr76q1XF0OQ1aUFAQLl++jDt37iiXVVVV4d69e8puGomJiWof6E2TSUdHR4OI1G43Nl07R0fHdsfYmq6UqzfffFNt2cWLF0FE8PHxAQBl0X525p/y8nI8evRI7dYpYLhcaYqLImMmRiqVwtPTEzk5OVpt13RrztzcXG15REQEvv32W+zduxdlZWW4du0aFixYAGdnZ4SEhGh9nOdNgxYcHAxHR8fnDl22ePFiuLu7Y+7cucjKykJRUREiIyNRXV2NZcuWaRXX05qunab9H9uqK+Xq/v372L9/P0pKSlBfX49z587hvffeg5ubGxYsWADgya3ScePGYefOnTh9+jSqq6uRnZ2tjPv3v/+92n4NlSuNkY7x04nNQyeZOojz2zba5j8sLIwsLCyoqqpKuezbb78lLy8vAkA9evRQPsH4rKVLl6o95t/Y2Ejx8fHUu3dvsrCwIHt7e/L396cbN24o22gzfVdr06AREfn7+xMAWrVq1XPPNTs7m95++22yt7cnKysreu211ygtLa3VbZ739Kmfnx+5uLiodet4nra8v7tKriIiIsjLy4usra1JJBKRq6srzZ8/n3Jzc1XaFRYWUnh4OHl7e5OVlRXZ2NjQyJEj6a9//Wuz+21rrrhLRgfHRbFr0zb/t27dIpFIRHv27NFjVPrT0NBAo0ePpt27dxv82IWFhSQWi2nDhg1ab9uW9zfnqu3akyt9FUW+fcqYCfL29kZMTAxiYmJaHRjbFDU0NCA1NRXl5eUIDg42+PHXrFmDIUOGICwszCDH41y1naFzpQkuioyZqKioKMyYMQPBwcEdaiDpU6dO4eDBg0hLS9O4/56ubNy4EVeuXMGxY8dgYWFhsONyrrRnrFw9j9GL4rPzjjW9LC0t0bNnT4wdOxbx8fEoLi42dqgmb8OGDcqn4b766itjh8N0IDY2FmFhYfj000+NHYrGxo8fj2+++QZOTk4GPe6hQ4dQW1uLU6dOwd7e3qDHBjhX2jB2rlpj9KL49Lxjtra2ICI0NjYiPz8fBw4cgIeHByIjIzFgwAC1x5SZqiVLluDs2bPGDoPp2IQJE/DZZ58ZOwyTN3XqVERFRak90WlInCvNmEKuWmL0otgcQRBgZ2eHsWPHIjExEQcOHMDDhw/h5+fXoW5NMP2orq5WGRasox6DMWZ6TLIoPiswMBBz585Ffn4+3xZk2L17t9rUNB3xGIwx09MhiiIAzJ07FwCQlpamXNbaPGHazDf2ww8/4LXXXoNUKoVcLsegQYNQVlb23GPoy+effw6pVAqZTIb8/HxERETAxcUFN27c0DqesLAwWFpaqvxmsHDhQlhbW0MQBLVxJ/WB6Pnzw2kaZ3h4OCIiIpCRkQFBEODt7Y0tW7ZALBajZ8+eCA0NhbOzM8RiMXx9fVUGUG7PMQDg+PHjkMvliI2N1ev1YowZka77eLS1H5uXlxfZ2tq2uL6srIwAUK9evZTLnjdPmCbzjVVUVJBcLqe4uDiqrq6mvLw8mj59OhUUFGh0DE1By35qTbF//PHHtHXrVpo+fTr98ssvz43n1q1bBIC+/PJL5b5mz55Njo6OKvuPj48nAMrz1FRb8qvp/HCaxhkQEEBeXl4q7UJCQsja2pquX79ONTU1lJ6eTsOHDyeZTEZZWVk6OcaRI0dIJpOpTN+jKW3zz4yD++F2HF2+n6JMJoMgCMqBcmtqapCQkAB/f38EBATAzs4OK1asgIWFBRITE1W29fX1hVwuh4ODA4KDg1FZWYmsrCwAQGZmJsrKyjBgwACIxWI4Ojri4MGD6NGjh1bH0JfPPvsMH374IQ4ePIgXX3zR6PFoq7q6Ghs3bsT06dMxZ84c2NraYtCgQfjqq69QWFiIHTt26OxYIpFI+W20f//+SEhIQHl5uc6ujZ+fH8rKyrBy5Uqd7I8xZno6TFGsrKwEEUEulwNo+zxhz8435unpiZ49e2LOnDlYs2YNMjMzlW11OReZLphaPJpo7/xw7TFs2DBIpVKTvTaMMdPTYYpi03xd/fr1A6A6T9jT/Rvv3buHqqoqjfcrkUjwt7/9DaNGjUJsbCw8PT0RHByM6upqnR1DV0wtHk3oen44bVlZWSlnVGCMsefpMEXx+PHjAICJEycC0O08YQMGDMB3332H3NxcREZGIikpCRs2bND7XGTaMrV4NKHr+eG0UV9fr/djMMY6lw5RFPPy8rBp0ya4urri3XffBaC7ecJyc3OVk5w6ODjg008/xdChQ3H9+nWdzkWmC22NRyQSKW8XG5o288PpOs5Tp06BiDBixAi9HYMx1rmYVFEkIlRUVKCxsVE5kWhSUhJGjhwJc3NzpKamKn9T1GSeME3k5uYiNDQUv/76K+rq6nD58mXcu3cPI0aM0NkxdKWt8Xh7e+PRo0dITU1FfX09CgoKcO/ePYPFrOn8cJrG2a1bN+Tm5iIzMxPl5eXKItfY2Iji4mI8fvwYV69eRXh4ONzc3JTdedp7jLS0NO6SwVhnp+vHWbV9pPnw4cM0ePBgkkqlZGlpSWZmZgSABEEgOzs7eu211ygmJoaKiorUtm1tnjBN5xvLzMwkX19fsre3J3Nzc3rhhRcoOjqaHj9+/NxjaANaPJIfFxdHEolE2QXl6SlpWovniy++IEdHRwJA1tbWNH36dCIiKioqonHjxpFYLCYPDw/66KOPaOnSpQSAvL29VbosPE9bHlnXZH44beK8dOkSubu7k0QioVGjRlFeXh6FhISQhYUFubi4kEgkIrlcTtOmTaOMjAydHePYsWMkk8lo3bp1Wp0/EXfJ6Ci4S0bHoa8uGQIRkS6L7IEDBxAUFAQd77bDEwQBSUlJmDlzprFDaRdTzW9oaCiSk5NRVFRk7FCa1Vny39mZ6vubqZsxYwYAIDk5Waf7Nanbp4y1R0NDg7FDYIx1cFwUGWOMMQUuiqzDW758ORITE1FaWgoPDw+kpKQYOyTGWAclMnYAjLXX+vXrsX79emOHwRjrBPibImOMMabARZExxhhT4KLIGGOMKXBRZIwxxhT09qBNU8dK9h+bNm3SeUdTQ8vJyQHA+W2LzpD/zo7f3x3H+fPnVcY11hWdj2hz7tw5bNy4UZe7ZKzTS0tLwyuvvAInJydjh8JYh+Hj44PFixfrdJ86L4qMMe3xMHCMmQb+TZExxhhT4KLIGGOMKXBRZIwxxhS4KDLGGGMKXBQZY4wxBS6KjDHGmAIXRcYYY0yBiyJjjDGmwEWRMcYYU+CiyBhjjClwUWSMMcYUuCgyxhhjClwUGWOMMQUuiowxxpgCF0XGGGNMgYsiY4wxpsBFkTHGGFPgosgYY4wpcFFkjDHGFLgoMsYYYwpcFBljjDEFLoqMMcaYAhdFxhhjTIGLImOMMabARZExxhhT4KLIGGOMKXBRZIwxxhS4KDLGGGMKXBQZY4wxBS6KjDHGmAIXRcYYY0yBiyJjjDGmIDJ2AIx1NSUlJSAiteWVlZUoLi5WWWZjYwMLCwtDhcZYlydQc3+djDG9eeONN/D3v//9ue3Mzc1x//59ODo6GiAqxhjAt08ZM7i3334bgiC02sbMzAz/7//9Py6IjBkYF0XGDCwwMBAiUeu/XAiCgN/+9rcGiogx1oSLImMGZm9vjwkTJsDc3LzFNmZmZvD39zdgVIwxgIsiY0YxZ84cNDY2NrtOJBLBz88Ptra2Bo6KMcZFkTEjmDJlCqysrJpd19DQgDlz5hg4IsYYwEWRMaOQSqXw9/dvtruFRCLBpEmTjBAVY4yLImNGMmvWLNTX16sss7CwQGBgICQSiZGiYqxr46LImJG8+eabar8b1tfXY9asWUaKiDHGRZExI7GwsEBwcDAsLS2Vy+zs7DB+/HgjRsVY18ZFkTEjevvtt1FXVwfgSZGcM2fOc/swMsb0h4d5Y8yIGhsb8cILL+Dhw4cAgDNnzmDkyJFGjoqxrou/KTJmRGZmZnjnnXcAAM7OzvD19TVyRIx1bWr3aXJycnD27FljxMJYl9SjRw8AwOuvv47k5GQjR8NY19GrVy/4+PioLqRnJCUlEQB+8Ytf/OIXvzr1KzAw8NkSSC3+os8/NTJ9OHDgAIKCgvj99YyUlBQEBga2uF4QBCQlJWHmzJkGjIppi9/fHceMGTOaXc6/KTJmAloriIwxw+GiyBhjjClwUWSMMcYUuCgyxhhjClwUGWOMMQUuiowxxpgCF0XWIR07dgy2trb47rvvjB0KY6wT4aLIOiTuB8YY0wcuim1QXV2t9zEqDXGMjszPzw+lpaWYPHmysUPhXDHWiXBRbIPdu3cjPz+/wx+D6QbnirHOo0sURSLCxo0b8dJLL8HKygr29vaYNm0afv31V2WbsLAwWFpawsnJSbls4cKFsLa2hiAIKCwsBACEh4cjIiICGRkZEAQB3t7e2LJlC8RiMXr27InQ0FA4OztDLBbD19cXFy5c0Mkx2H+cOXMGbm5uEAQB27ZtAwAkJCTA2toaUqkUhw4dwsSJEyGXy+Hq6op9+/YptzVUro4fPw65XI7Y2FhDXBLGmK60NCB4Z7Jq1SqytLSkPXv2UElJCV29epWGDh1KPXr0oLy8PGW72bNnk6Ojo8q28fHxBIAKCgqUywICAsjLy0ulXUhICFlbW9P169eppqaG0tPTafjw4SSTySgrK0snx+gMdPX+ys7OJgC0detW5bLo6GgCQCdPnqTS0lLKz8+n0aNHk7W1NdXV1SnbGSJXR44cIZlMRjExMe0+VyIiAJSUlKSTfTH96Yyfn51VYGBgswOCd/pvitXV1di4cSOmT5+OOXPmwNbWFoMGDcJXX32FwsJC7NixQ2fHEolEym+j/fv3R0JCAsrLy5GYmKizY7Dn8/X1hVwuh4ODA4KDg1FZWYmsrCyVNvrOlZ+fH8rKyrBy5Uqd7I8xZhidviimp6ejoqICw4YNU1k+fPhwWFpaqtwy07Vhw4ZBKpWq3KZlhmVpaQkAqK+vb7Ud54oxBnSBolhSUgIAsLGxUVtnZ2eH8vJyvR7fysoKBQUFej0G0w3OFWOs0xdFOzs7AGi2+JWUlMDV1VVvx66vr9f7MZhucK4YY0AXKIoDBw6EjY0NfvzxR5XlFy5cQF1dHV599VXlMpFI9NzbbNo4deoUiAgjRozQ2zGYbnCuGGNAFyiKYrEYERER+Pbbb7F3716UlZXh2rVrWLBgAZydnRESEqJs6+3tjUePHiE1NRX19fUoKCjAvXv31PbZrVs35ObmIjMzE+Xl5coPzsbGRhQXF+Px48e4evUqwsPD4ebmhrlz5+rsGEw39J2rtLQ07pLBWAfU6YsiAKxevRrr169HTEwMevTogTFjxuDFF1/EqVOnYG1trWz3wQcfYNy4cXj77bfRt29frF27FhKJBADg4+OD7OxsAMCCBQvQs2dP9O/fH5MmTcKjR48AADU1NRg0aBAkEglGjx6NPn364O9//zusrKx0dgwGbNu2DcOHDwcAREZGYurUqUhISMCmTZsAAIMHD8adO3ewc+dOREREAADeeust3Lp1S7kPzhVjrDkCkeogkgcOHEBQUBCPLaml0NBQJCcno6ioyNihmDRTeH91xFwJgoCkpCTMnDnT2KGwVpjC+5tpZsaMGQCA5ORkleVd4puioTQ0NBg7BKYhzhVjrDlcFBnr5E6cOIGoqCgcPHgQnp6eEAQBgiDgnXfeUWs7YcIEyGQymJubY8CAAbh06ZIRItbcunXrlOfz9GvgwIFqbf/yl79g+PDhkMlkcHd3x7x585CXl6dcf/jwYcTFxRn1P0ydOVdNGhsbsWnTplYH0T9z5gxGjhwJqVQKZ2dnREZGora2Vrler7l6dogbHqZIe1FRUWRpaUkA6MUXX6Tk5GRjh2SyjP3+6qi5QhuHeVu1ahVNnjyZysrKlMu8vLyoe/fuBICOHDmitk1aWhpNnTq1XfEaytq1awmA2mvAgAEq7fbv308AKC4ujkpKSujy5cvk6elJQ4YMofr6emW7zZs305gxY6i4uLhN8bTn/d3Zc0VEdPPmTRo5ciQBoJdffrnZNj///DNJJBJauXIlVVRU0NmzZ6lHjx40b948lXbtzVVLw7xxUWQGxe+vtmlLUfz000+pT58+VF1drbLcy8uLvvnmGzIzMyMXFxcqKSlRWd+RPmjXrl1Le/bseW67cePG0QsvvECNjY3KZdu2bSMAdObMGZW2YWFh5OPjo1IsNdXW93dXyNWVK1do+vTptHfvXhoyZEiLRTEoKIg8PDxUchUfH0+CINAvv/yi0rY9ueqyY58y1hXdvn0bK1euxCeffAKxWKy23tfXF+Hh4bh//z6WLFlihAgNKzs7G87OzhAEQbmsV69eAKDWzWbNmjW4cuUKNm/ebJDYukquXn75ZRw8eBCzZ89Wecr7aY8fP8bRo0cxZswYlVxNnDgRRIRDhw6ptNdHrrgoMtYJbdmyBUSEKVOmtNhm3bp16NOnD3bt2oUTJ060uj/SYPo1TafvAp486LRq1Sq4ublBIpFg8ODBSEpKat9Jt8LT01Ntzsum3xM9PT1Vltvb22PMmDHYvHmzQZ4i5Vz9x507d1BRUQE3NzeV5V5eXgCAq1evqizXR664KDLWCR09ehR9+/aFVCptsY1EIsEf//hHmJmZYf78+aisrGyx7Zo1axAVFYXo6Gjk5+fj9OnTyM7OxujRo/Hw4UMAT/p1Llq0CNXV1ZDJZEhKSkJGRgY8PT0xf/58lQEoli1bhs8//xybNm3CgwcPMHnyZMyaNUtt5ClNREVFwd7eHpaWlvDw8MC0adNw8eJFlTbLly9HXl4etm7divLycqSnp2Pz5s148803VUYxavLKK6/g/v37+Omnn7SOR1tdKVfP0/QfFZlMprJcLBZDIpEo43+arnPFRZGxTqayshJ3795V/u+6NT4+Pli0aBEyMzOxbNmyZtu0Zfq11qbvqqmpQUJCAvz9/REQEAA7OzusWLECFhYWWk/d9bvf/Q6HDx9GdnY2KioqsG/fPmRlZWHMmDFIT09XthszZgwiIyMRFhYGuVyOgQMHory8HLt27Wp2v7179wYAXLt2Tat4tNWVcqWJpidMzc3N1dZZWFigurpabbmucyVqaUVTx0bGdCknJwcAv7/0KT8/H0TU6jePp61btw5HjhzB9u3bERQUpLa+vdOvPTt9140bN1BVVaXSbUIikcDJyUnrqbt69eql/G0QAEaMGIHExEQMGTIE27dvR0JCAgAgOjoau3btwsmTJ/H6668jPz8fy5Ytg4+PD86ePauyDwDKa9fcNxNd6kq50kTTb6qPHz9WW1dXV6ccUeppus4Vf1PUUEpKivIDnTFTVlNTAwAtPszwLLFYjMTERAiCgHfffVftf+O6nn6t6dbfihUrVPoW3rt3D1VVVVrtqzmDBg2Cubk5bt68CQB48OAB4uLi8P777+ONN96AtbU1PDw8sHPnTuTm5iI+Pl5tH00fvk3XUl+6eq6e5eTkBAAoKytTWV5VVYWamho4OzurbaPrXLX4TfHZoW+6OkEQsGjRIh5mq52ahsHi95d2nn4S73maPiS06djs4+ODxYsXY8OGDVi7dq3Kgw66nn7NwcEBALBp0yaEh4drta0mGhsb0djYqCw0t27dQkNDA1544QWVdnK5HN26dVO5zdqkrq4OAJr9ZqJLXT1Xz/Lw8IBMJlN7Ivj27dsAnoxr/Cxd54q/KTLWyfTs2ROCIKC0tFSr7dauXYt+/frh8uXLKsu1mX5NE7169YJYLMaVK1e02q45b775ptqyixcvgojg4+MDAMpC8ODBA5V25eXlePTokdqtUwDKa+fo6NjuGFvTlXKlCZFIhEmTJuH06dNobGxULk9LS4MgCM0+oavrXHFRZKyTkUql8PT01Pp2f9OtuWcfctBm+jVNjzNv3jzs27cPCQkJKCsrQ0NDA3JycpSFKzg4GI6Ojs8duuz+/fvYv38/SkpKUF9fj3PnzuG9996Dm5sbFixYAODJt49x48Zh586dOH36NKqrq5Gdna2M+/e//73afpuu3aBBg7Q6N211pVxpauXKlXj48CFWr16NyspKnDt3DvHx8Zg7dy769u2r1l7nuXq2Nz+PONI8tHGYLaaK319to+37LywsjCwsLKiqqkq57NtvvyUvLy8CQD169KAPP/yw2W2XLl2qNkpKY2MjxcfHU+/evcnCwoLs7e3J39+fbty4oWyzfft2kkqlBIB69+5NGRkZtGPHDpLL5QSA3N3d6ebNm0REVFtbS5GRkeTm5kYikYgcHBwoICCA0tPTiYjI39+fANCqVataPc+IiAjy8vIia2trEolE5OrqSvPnz6fc3FyVdoWFhRQeHk7e3t5kZWVFNjY2NHLkSPrrX//a7H79/PzIxcVFZVQVTbTl/d1VcnXu3DkaOXIkOTs7K4fjc3JyIl9fX/rhhx9U2v7www/02muvkZWVFTk7O9PSpUuppqam2f22NVc8zFs7cVHUDX5/tY22779bt26RSCTSaAg0U9TQ0ECjR4+m3bt3G/zYhYWFJBaLacOGDVpv25b3N+eq7dqTKx7mjbEuxNvbGzExMYiJiUFFRYWxw9FKQ0MDUlNTUV5ejuDgYIMff82aNRgyZAjCwsIMcjzOVdvpI1ftLorPTnHS9LK0tETPnj0xduxYxMfHo7i4WBfxdjm1tbX4+OOP4eTkBKlUiuPHjxs7JNZBREVFYcaMGQgODtb6QQ5jOnXqFA4ePIi0tDSN++/pysaNG3HlyhUcO3YMFhYWBjsu50p7+spVu4tiQEAA7ty5Ay8vL9ja2oKI0NjYiPz8fBw4cAAeHh6IjIzEgAED9DIsUGf3xRdf4Pjx4/j111+xefPmDvc/SWZcsbGxCAsLw6effmrsUDQ2fvx4fPPNN8o+a4Zy6NAh1NbW4tSpU7C3tzfosQHOlTb0masW+ym2hyAIsLOzw9ixYzF27Fj4+fkhKCgIfn5+uHnzJmxtbfVx2E4pNTUVw4YNg52dHd5//30AT4ZyGj9+PM6ePWvk6DomQ1w/U8rRhAkTMGHCBGOHYfKmTp2KqVOnGjUGzpVm9JkrQoZxYAAACA1JREFUg/ymGBgYiLlz5yI/Px9fffWVIQ7ZaeTk5KjdGti9e7faiP9Mc4a4fpwjxjomgz1oM3fuXABPOmE2aW1KEm2mNvnhhx/w2muvQSqVQi6XY9CgQcphggw9RY0mMZEGU7v83//9H7y9vfHgwQP86U9/giAIsLGxQXh4OCIiIpCRkQFBEODt7Y3NmzfD2toaZmZmePXVV+Ho6AgLCwtYW1tj6NChGD16tLITrp2dHf7whz+oxPqPf/wD/fv3h62tLcRiMQYNGoTvv/8eAPDHP/4RNjY2EAQB9vb2SE1NxY8//gh3d3eYm5tj1qxZer+WmlyvsLAwWFpaqtzGWbhwIaytrSEIAgoLCwGg2eu3ZcsWiMVi9OzZE6GhoXB2doZYLIavr6/KWJHtOQYAHD9+HHK5HLGxsXq9Xoyxdnj2cdS2PjLv5eVFtra2La4vKysjANSrVy/lsiVLlpCVlRWlpKRQcXExLV++nMzMzOjixYtERBQdHU0A6OTJk1RaWkr5+fk0evRosra2prq6OiIiqqioILlcTnFxcVRdXU15eXk0ffp0Kigo0OgYmoIWj8Q/L6ZVq1aRpaUl7dmzh0pKSujq1as0dOhQ6tGjB+Xl5ansy9HRkX73u9+pLAsICCAvLy+VZatXryYAdOHCBaqsrKTCwkJ66623CAAdPXqUCgoKqLKyksLCwggAXblyRbltcnIyrVmzhh49ekRFRUU0YsQI6t69u3L99evXSSqVqsQRFRVFu3bt0uh6PK0t7y9Nr9fs2bPJ0dFRZdv4+HgCoLz2RM1fv5CQELK2tqbr169TTU0Npaen0/Dhw0kmk1FWVpZOjnHkyBGSyWQUExOj1fkTcZegjoK7HHUcRu+SIZPJIAiCckw+baYkaW1qk8zMTJSVlWHAgAEQi8VwdHTEwYMH0aNHD4NPe9KktZjaMrWLNvr37w+pVIru3bvj7bffBgC4ubmhR48ekEqlmDNnDgCofMsKDAzE6tWrYW9vj27dumHKlCkoKipCQUEBAOCll17Cpk2b8Kc//QnffPMN9u3bh9ra2mZHAtE1fV+vp4lEIuW30f79+yMhIQHl5eU6e6/4+fmhrKwMK1eu1Mn+GGO6Z7CiWFlZCSKCXC4H0PYpSZ6d2sTT0xM9e/bEnDlzsGbNGmRmZirbGnrakyatxdTeqV200XStnp6Gpen3yacnEX1WU5unByl+//33ERgYiNDQUBw4cACff/65zuJsjSGv17OGDRsGqVSq1/cKY8y0GKwoNk3j0q9fPwC6m5JEIpHgb3/7G0aNGoXY2Fh4enoiODgY1dXVBp/2RJOYdD21iy4cPXoUY8eOhYODA6ysrNR+c2wSGxuLiooKgz5AYuzrZWVlpfzGzBjr/AxWFJs6nU+cOBGA6pQk9GS4OeXr3LlzWu17wIAB+O6775Cbm4vIyEgkJSVhw4YNOj2GtlqKSddTu7RXVlYW/P394eTkhAsXLqC0tBRxcXFq7err6/Hxxx9j48aNOHfuHNatW2eQ+Ix5verr642SE8aY8RikKObl5WHTpk1wdXXFu+++C0B3U5Lk5ubi+vXrAJ4U2k8//RRDhw7F9evXDT7tiSYx6Xpql/a6du0a6uvr8cEHH8DT0xNisbjZufs++ugjzJ8/H4sWLcLixYuxdu1avf/HAtBuKhyRSNTqbWFtnTp1CkSEESNG6O0YjDHTotOiSESoqKhAY2MjiAgFBQVISkrCyJEjYW5ujtTUVOVvippMSaKJ3NxchIaG4tdff0VdXR0uX76Me/fuYcSIETo7hraeF1N7p3bp1q0bcnNzkZmZifLy8nZ9SDdNUHrixAnU1NTg1q1bar/Tbd++HS4uLpg+fToAYP369ejfvz9mz56tNkO2rmlzvby9vfHo0SOkpqaivr4eBQUFapOVAi1fv8bGRhQXF+Px48e4evUqwsPD4ebmpuxO1N5jpKWlcZcMxkzds4+javtI8eHDh2nw4MEklUrJ0tKSzMzMCAAJgkB2dnb02muvUUxMDBUVFalt29qUJJpObZKZmUm+vr5kb29P5ubm9MILL1B0dDQ9fvz4ucfQBrR4JP55MWkytUtmZia98sorBIBEIhENHTqUUlJSiIjo0qVL5O7uThKJhEaNGkVRUVHKa/Xiiy/+//buHlVxKAzj+BtQsNFoGguxCLoAW0t3YBNdgjYWFiJYi7gAeyvxI9ZuQEjlFuwsbFK4gmea3Mu93hnGGWZQr/8fvM1B8Hhy4CHE90T7/V7T6VSu68rMVCwWtVgstFqtVCwWZWYqFApaLpeSpOFwKM/zlM/nFQSBZrOZzEyVSkW1Wk2O48jzPEVRJEnq9/vv19l1XR0Oh5vX8W/+sn7LeklSHMdqNBrKZDLyfV+9Xk+DwUBmpmq1+t5acb1+5/NZnU5H6XRapVJJqVRKuVxOzWZTx+Pxn33HbrdTNpvVeDz+o98v0ZLxLGjJeB6/aslwJOljSG42G2u323Y1/PIcx7H1em2tVuveU3lqj7q/ut2uhWFocRzfeyo/xf57Do+6v/FVEARmZhaG4adxXh0FJD62oAB4TYQiAAAJQhEvbzQa2Xw+t8vlYr7v23a7vfeUANzJf3l1FPBMJpOJTSaTe08DwAPgThEAgAShCABAglAEACBBKAIAkCAUAQB4c33EzdsxRRRFURT1neumY95Op5NFUWQAAHxn5XLZ6vX6p7EvoQgAwKvimSIAAAlCEQCABKEIAEAiZWbhbz8FAMAL+AGFdJOc2won3QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "execution_count": 266
        }
      ],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model_1, show_shapes=True, show_layer_activations=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "id": "RocJq6Nb5jSa"
      },
      "outputs": [],
      "source": [
        "model_2 = models.Sequential()\n",
        "\n",
        "if first_population_integers[1] != 0:\n",
        "  model_2.add(layers.Dense(first_population_integers[1], activation='relu', name='hidden', input_dim=64))\n",
        "  model_2.add(layers.Dense(10, activation='softmax', name='output'))\n",
        "else:\n",
        "  model_2.add(layers.Dense(10, activation='softmax', name='output', input_dim=64))\n",
        "\n",
        "model_2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {
        "id": "2yPuSie05mGm"
      },
      "outputs": [],
      "source": [
        "model_3 = models.Sequential()\n",
        "\n",
        "if first_population_integers[2] != 0:\n",
        "  model_3.add(layers.Dense(first_population_integers[2], activation='relu', name='hidden', input_dim=64))\n",
        "  model_3.add(layers.Dense(10, activation='softmax', name='output'))\n",
        "else:\n",
        "  model_3.add(layers.Dense(10, activation='softmax', name='output', input_dim=64))\n",
        "\n",
        "model_3.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "id": "8l-gbtKf5npR"
      },
      "outputs": [],
      "source": [
        "model_4 = models.Sequential()\n",
        "\n",
        "if first_population_integers[3] != 0:\n",
        "  model_4.add(layers.Dense(first_population_integers[3], activation='relu', name='hidden', input_dim=64))\n",
        "  model_4.add(layers.Dense(10, activation='softmax', name='output'))\n",
        "else:\n",
        "  model_4.add(layers.Dense(10, activation='softmax', name='output', input_dim=64))\n",
        "\n",
        "model_4.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "id": "OGOnXfJ65phq"
      },
      "outputs": [],
      "source": [
        "model_5 = models.Sequential()\n",
        "\n",
        "if first_population_integers[4] != 0:\n",
        "  model_5.add(layers.Dense(first_population_integers[4], activation='relu', name='hidden', input_dim=64))\n",
        "  model_5.add(layers.Dense(10, activation='softmax', name='output'))\n",
        "else:\n",
        "  model_5.add(layers.Dense(10, activation='softmax', name='output', input_dim=64))\n",
        "\n",
        "model_5.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {
        "id": "-j0eCOUY5rr4"
      },
      "outputs": [],
      "source": [
        "model_6 = models.Sequential()\n",
        "\n",
        "if first_population_integers[5] != 0:\n",
        "  model_6.add(layers.Dense(first_population_integers[5], activation='relu', name='hidden', input_dim=64))\n",
        "  model_6.add(layers.Dense(10, activation='softmax', name='output'))\n",
        "else:\n",
        "  model_6.add(layers.Dense(10, activation='softmax', name='output', input_dim=64))\n",
        "\n",
        "model_6.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUDmWAGgpHwB"
      },
      "source": [
        "---\n",
        "\n",
        "# **4. Downloading dataset -> preprocessing**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "id": "7Xx1MFMspVbi"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {
        "id": "zNIzjlSlpccz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d525f7e-def1-4f43-d227-816d34629643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1797, 64)\n"
          ]
        }
      ],
      "source": [
        "input, targets = load_digits(return_X_y=True)\n",
        "\n",
        "print(input.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {
        "id": "c2goT-vHpn_S"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "id": "TGpCtKCHpseV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecdc55de-514f-4412-d499-3f1379fb10fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.    , 0.    , 0.3125, ..., 0.    , 0.    , 0.    ],\n",
              "       [0.    , 0.    , 0.    , ..., 0.625 , 0.    , 0.    ],\n",
              "       [0.    , 0.    , 0.    , ..., 1.    , 0.5625, 0.    ],\n",
              "       ...,\n",
              "       [0.    , 0.    , 0.0625, ..., 0.375 , 0.    , 0.    ],\n",
              "       [0.    , 0.    , 0.125 , ..., 0.75  , 0.    , 0.    ],\n",
              "       [0.    , 0.    , 0.625 , ..., 0.75  , 0.0625, 0.    ]])"
            ]
          },
          "metadata": {},
          "execution_count": 275
        }
      ],
      "source": [
        "MinMaxScaler(copy=False).fit_transform(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "id": "J0aixZGFrAlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f7c077c-dca3-4a9d-a1e9-674393f70ef3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 276
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "targets = to_categorical(targets) # for instance -> [0,1,0,0,0,0,0,0,0,0] -> number 1 and so on...\n",
        "\n",
        "targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRIFF6QWr9f2"
      },
      "source": [
        "---\n",
        "\n",
        "# **5. Dividing dataset into train and test** \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "id": "IQOkZlJzr7NA"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "id": "7SsAKYw-sU35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f56da366-c50d-4655-c5ce-d753d55e14b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1347, 64), (450, 64), (1347, 10), (450, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 278
        }
      ],
      "source": [
        "input_train, input_test, targets_train, targets_test = train_test_split(input, targets, test_size=0.25, stratify=targets, random_state=42)\n",
        "\n",
        "input_train.shape, input_test.shape, targets_train.shape, targets_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVcz-JOetEvB"
      },
      "source": [
        "---\n",
        "\n",
        "# **6. Fit models**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "id": "g6sJKhz54W1R"
      },
      "outputs": [],
      "source": [
        "n_epochs = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "id": "zZbki4Zq48uK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a57f93d6-ef49-42ff-80ee-8a9a07a25038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 7ms/step - loss: 1.9341 - accuracy: 0.4722 - val_loss: 1.6196 - val_accuracy: 0.7489\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.4138 - accuracy: 0.8174 - val_loss: 1.1838 - val_accuracy: 0.8289\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.0265 - accuracy: 0.8738 - val_loss: 0.8621 - val_accuracy: 0.8711\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.7441 - accuracy: 0.8968 - val_loss: 0.6424 - val_accuracy: 0.8911\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.5615 - accuracy: 0.9161 - val_loss: 0.5081 - val_accuracy: 0.8933\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.9280 - val_loss: 0.4078 - val_accuracy: 0.9222\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.9347 - val_loss: 0.3555 - val_accuracy: 0.9289\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3007 - accuracy: 0.9451 - val_loss: 0.3149 - val_accuracy: 0.9133\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2617 - accuracy: 0.9525 - val_loss: 0.2736 - val_accuracy: 0.9289\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2280 - accuracy: 0.9569 - val_loss: 0.2519 - val_accuracy: 0.9467\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2045 - accuracy: 0.9584 - val_loss: 0.2353 - val_accuracy: 0.9356\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.1851 - accuracy: 0.9681 - val_loss: 0.2130 - val_accuracy: 0.9511\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1697 - accuracy: 0.9651 - val_loss: 0.1968 - val_accuracy: 0.9511\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.9733 - val_loss: 0.1821 - val_accuracy: 0.9600\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9725 - val_loss: 0.1843 - val_accuracy: 0.9511\n"
          ]
        }
      ],
      "source": [
        "fit_1 = model_1.fit(input_train, targets_train, epochs=n_epochs, validation_data=(input_test, targets_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix3jKt9l4_D5",
        "outputId": "8d70e14f-70ed-49c0-b918-9ca44f0b0bec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 8ms/step - loss: 2.0366 - accuracy: 0.3794 - val_loss: 1.7524 - val_accuracy: 0.6133\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.5382 - accuracy: 0.7186 - val_loss: 1.3240 - val_accuracy: 0.8200\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.1477 - accuracy: 0.8263 - val_loss: 1.0042 - val_accuracy: 0.8200\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.8518 - accuracy: 0.8738 - val_loss: 0.7528 - val_accuracy: 0.8778\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.8968 - val_loss: 0.5810 - val_accuracy: 0.8933\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.9117 - val_loss: 0.4637 - val_accuracy: 0.9133\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3953 - accuracy: 0.9317 - val_loss: 0.3930 - val_accuracy: 0.9089\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3269 - accuracy: 0.9480 - val_loss: 0.3333 - val_accuracy: 0.9244\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2785 - accuracy: 0.9495 - val_loss: 0.2952 - val_accuracy: 0.9311\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2415 - accuracy: 0.9547 - val_loss: 0.2648 - val_accuracy: 0.9333\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.9607 - val_loss: 0.2415 - val_accuracy: 0.9333\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.1905 - accuracy: 0.9607 - val_loss: 0.2237 - val_accuracy: 0.9333\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1735 - accuracy: 0.9666 - val_loss: 0.2100 - val_accuracy: 0.9333\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1571 - accuracy: 0.9688 - val_loss: 0.1942 - val_accuracy: 0.9444\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9710 - val_loss: 0.1981 - val_accuracy: 0.9378\n"
          ]
        }
      ],
      "source": [
        "fit_2 = model_2.fit(input_train, targets_train, epochs=n_epochs, validation_data=(input_test, targets_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "id": "SXPC8v9m5BEC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5365ec01-e2a0-49f0-820a-e8a25d8674e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 7ms/step - loss: 2.1833 - accuracy: 0.2146 - val_loss: 1.9616 - val_accuracy: 0.4378\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.8008 - accuracy: 0.6036 - val_loss: 1.6314 - val_accuracy: 0.6600\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.4632 - accuracy: 0.7454 - val_loss: 1.3040 - val_accuracy: 0.7711\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.1598 - accuracy: 0.8166 - val_loss: 1.0271 - val_accuracy: 0.8111\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.9126 - accuracy: 0.8567 - val_loss: 0.8272 - val_accuracy: 0.8422\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.7334 - accuracy: 0.8857 - val_loss: 0.6698 - val_accuracy: 0.8889\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.9035 - val_loss: 0.5561 - val_accuracy: 0.8978\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.9094 - val_loss: 0.4679 - val_accuracy: 0.9156\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.9206 - val_loss: 0.4057 - val_accuracy: 0.9156\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.9376 - val_loss: 0.3566 - val_accuracy: 0.9244\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3124 - accuracy: 0.9451 - val_loss: 0.3185 - val_accuracy: 0.9400\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2760 - accuracy: 0.9465 - val_loss: 0.2871 - val_accuracy: 0.9311\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.9540 - val_loss: 0.2652 - val_accuracy: 0.9400\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2256 - accuracy: 0.9584 - val_loss: 0.2493 - val_accuracy: 0.9422\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2067 - accuracy: 0.9592 - val_loss: 0.2297 - val_accuracy: 0.9422\n"
          ]
        }
      ],
      "source": [
        "fit_3 = model_3.fit(input_train, targets_train, epochs=n_epochs, validation_data=(input_test, targets_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {
        "id": "YFomvYOJ5Fzu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a7cc37b-69d2-4c77-aef0-60f8a511f8c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 7ms/step - loss: 2.2694 - accuracy: 0.1247 - val_loss: 2.1632 - val_accuracy: 0.2067\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 2.0612 - accuracy: 0.3356 - val_loss: 1.9759 - val_accuracy: 0.4222\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 1.8766 - accuracy: 0.4915 - val_loss: 1.7970 - val_accuracy: 0.5578\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.6999 - accuracy: 0.6088 - val_loss: 1.6221 - val_accuracy: 0.6422\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.5259 - accuracy: 0.6845 - val_loss: 1.4547 - val_accuracy: 0.7267\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.3600 - accuracy: 0.7402 - val_loss: 1.2940 - val_accuracy: 0.7533\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.2005 - accuracy: 0.7921 - val_loss: 1.1434 - val_accuracy: 0.7778\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.0551 - accuracy: 0.8278 - val_loss: 1.0131 - val_accuracy: 0.8178\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.9282 - accuracy: 0.8478 - val_loss: 0.8967 - val_accuracy: 0.8333\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.8222 - accuracy: 0.8664 - val_loss: 0.8041 - val_accuracy: 0.8533\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.7294 - accuracy: 0.8797 - val_loss: 0.7246 - val_accuracy: 0.8511\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.8894 - val_loss: 0.6572 - val_accuracy: 0.8756\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.8976 - val_loss: 0.5954 - val_accuracy: 0.8800\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.9072 - val_loss: 0.5501 - val_accuracy: 0.8778\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.9124 - val_loss: 0.5072 - val_accuracy: 0.8822\n"
          ]
        }
      ],
      "source": [
        "fit_4 = model_4.fit(input_train, targets_train, epochs=n_epochs, validation_data=(input_test, targets_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNybUWS65JMX",
        "outputId": "a144f5f7-daa6-48a5-f058-6f6e500b8965"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 7ms/step - loss: 2.2552 - accuracy: 0.2272 - val_loss: 2.1014 - val_accuracy: 0.3044\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.9500 - accuracy: 0.4172 - val_loss: 1.8252 - val_accuracy: 0.4844\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.6739 - accuracy: 0.5746 - val_loss: 1.5515 - val_accuracy: 0.6333\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.4032 - accuracy: 0.6993 - val_loss: 1.2928 - val_accuracy: 0.7444\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.1606 - accuracy: 0.8018 - val_loss: 1.0744 - val_accuracy: 0.8022\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.9604 - accuracy: 0.8471 - val_loss: 0.8935 - val_accuracy: 0.8644\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.7984 - accuracy: 0.8805 - val_loss: 0.7552 - val_accuracy: 0.8711\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.6752 - accuracy: 0.8938 - val_loss: 0.6518 - val_accuracy: 0.8756\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.9050 - val_loss: 0.5686 - val_accuracy: 0.8889\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.9065 - val_loss: 0.5078 - val_accuracy: 0.8911\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.9161 - val_loss: 0.4596 - val_accuracy: 0.9022\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.9228 - val_loss: 0.4104 - val_accuracy: 0.9111\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.9339 - val_loss: 0.3847 - val_accuracy: 0.8978\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3278 - accuracy: 0.9384 - val_loss: 0.3468 - val_accuracy: 0.9289\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3001 - accuracy: 0.9391 - val_loss: 0.3241 - val_accuracy: 0.9222\n"
          ]
        }
      ],
      "source": [
        "fit_5 = model_5.fit(input_train, targets_train, epochs=n_epochs, validation_data=(input_test, targets_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwXuEZkV5MWt",
        "outputId": "1641447c-1ab9-4526-f7cb-51c0036dafc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 7ms/step - loss: 2.1001 - accuracy: 0.2992 - val_loss: 1.8862 - val_accuracy: 0.5200\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.7499 - accuracy: 0.6199 - val_loss: 1.5939 - val_accuracy: 0.7044\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.4614 - accuracy: 0.7654 - val_loss: 1.3181 - val_accuracy: 0.8333\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.1928 - accuracy: 0.8404 - val_loss: 1.0652 - val_accuracy: 0.8756\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.9544 - accuracy: 0.8812 - val_loss: 0.8618 - val_accuracy: 0.8978\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.7605 - accuracy: 0.9027 - val_loss: 0.6960 - val_accuracy: 0.8933\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.9131 - val_loss: 0.5785 - val_accuracy: 0.9133\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.9272 - val_loss: 0.4929 - val_accuracy: 0.9133\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.9369 - val_loss: 0.4214 - val_accuracy: 0.9244\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3635 - accuracy: 0.9406 - val_loss: 0.3722 - val_accuracy: 0.9289\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3175 - accuracy: 0.9436 - val_loss: 0.3432 - val_accuracy: 0.9244\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2845 - accuracy: 0.9488 - val_loss: 0.3184 - val_accuracy: 0.9311\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.9517 - val_loss: 0.2889 - val_accuracy: 0.9356\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2341 - accuracy: 0.9525 - val_loss: 0.2724 - val_accuracy: 0.9311\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2171 - accuracy: 0.9607 - val_loss: 0.2523 - val_accuracy: 0.9444\n"
          ]
        }
      ],
      "source": [
        "fit_6 = model_6.fit(input_train, targets_train, epochs=n_epochs, validation_data=(input_test, targets_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1tc5ViKA3yB"
      },
      "source": [
        "---\n",
        "\n",
        "# **7. Genetic part and very first new sizes population**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "id": "VpucNAf_Da4f"
      },
      "outputs": [],
      "source": [
        "def fitness_function(fit_1, fit_2, fit_3, fit_4, fit_5, fit_6):\n",
        "  fitness_list = []\n",
        "\n",
        "  model_1_loss = sum(fit_1.history['loss'])\n",
        "  model_2_loss = sum(fit_2.history['loss'])\n",
        "  model_3_loss = sum(fit_3.history['loss'])\n",
        "  model_4_loss = sum(fit_4.history['loss'])\n",
        "  model_5_loss = sum(fit_5.history['loss'])\n",
        "  model_6_loss = sum(fit_6.history['loss'])\n",
        "\n",
        "  fitness_list.append(model_1_loss)\n",
        "  fitness_list.append(model_2_loss)\n",
        "  fitness_list.append(model_3_loss)\n",
        "  fitness_list.append(model_4_loss)\n",
        "  fitness_list.append(model_5_loss)\n",
        "  fitness_list.append(model_6_loss)\n",
        "\n",
        "  return fitness_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IOge3_9Dznc",
        "outputId": "6448b119-1a4b-4b7a-e4c0-097288600abe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model 1 loss: 8.120949909090996\n",
            "model 2 loss: 8.832607686519623\n",
            "model 3 loss: 11.390152722597122\n",
            "model 4 loss: 17.778234094381332\n",
            "model 5 loss: 13.804473102092743\n",
            "model 6 loss: 11.43119104206562\n",
            "average models loss: 11.892934759457907\n",
            "first population integers:\n",
            "[58, 54, 35, 12, 23, 37]\n",
            "1 - normalized fitnesses:\n",
            "[0.5432082924559106, 0.50317856995082, 0.35932035419665853, 0.0, 0.2235183185907348, 0.35701200797674526]\n"
          ]
        }
      ],
      "source": [
        "fitness_list = fitness_function(fit_1, fit_2, fit_3, fit_4, fit_5, fit_6)\n",
        "\n",
        "print(\"model 1 loss: \" + str(fitness_list[0]))\n",
        "print(\"model 2 loss: \" + str(fitness_list[1]))\n",
        "print(\"model 3 loss: \" + str(fitness_list[2]))\n",
        "print(\"model 4 loss: \" + str(fitness_list[3]))\n",
        "print(\"model 5 loss: \" + str(fitness_list[4]))\n",
        "print(\"model 6 loss: \" + str(fitness_list[5]))\n",
        "\n",
        "norm = [float(i)/max(fitness_list) for i in fitness_list]\n",
        "\n",
        "norm = [1 - i for i in norm]\n",
        "\n",
        "av = (fitness_list[0] + fitness_list[1] + fitness_list[2] + fitness_list[3] + fitness_list[4] + fitness_list[5]) / 6.0\n",
        "print(\"average models loss: \" + str(av))\n",
        "\n",
        "print(\"first population integers:\")\n",
        "print(first_population_integers)\n",
        "\n",
        "print(\"1 - normalized fitnesses:\")\n",
        "print(norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "id": "SiffT6DqA8Lu"
      },
      "outputs": [],
      "source": [
        "def calculate_probability_of_occurrence(fitness_list):\n",
        "    sum = 0.0\n",
        "\n",
        "    probabilities_list = []\n",
        "\n",
        "    for i in fitness_list:\n",
        "        sum += i\n",
        "\n",
        "    for i in range(len(fitness_list)):\n",
        "        probabilities_list.append(math.floor(fitness_list[i] / sum * 100))\n",
        "\n",
        "    return probabilities_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTenOm5TEssp",
        "outputId": "d05559ef-7656-4260-9d4a-562d2937df42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[27, 25, 18, 0, 11, 17]"
            ]
          },
          "metadata": {},
          "execution_count": 289
        }
      ],
      "source": [
        "probabilities_list = calculate_probability_of_occurrence(norm)\n",
        "\n",
        "probabilities_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "id": "JhqLk4JARf31"
      },
      "outputs": [],
      "source": [
        "def generate_list_of_probabilities(probabilities_list, population_integers):\n",
        "    long_list = []\n",
        "\n",
        "    for i in range(len(population_integers)):\n",
        "        for j in range(probabilities_list[i]):\n",
        "            long_list.append(population_integers[i])\n",
        "\n",
        "    return long_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDDqnCdIRkLc",
        "outputId": "60068533-20d9-4159-ed10-e15e08edd9b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 58 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 23 23 23 23 23 23 23 23 23 23 23 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37\n"
          ]
        }
      ],
      "source": [
        "long_list = generate_list_of_probabilities(probabilities_list, first_population_integers)\n",
        "\n",
        "print(*long_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "id": "pGvdN_RiTvvk"
      },
      "outputs": [],
      "source": [
        "def crossover(first_parent, second_parent):\n",
        "    start_to_middle_len = random.randint(1, chromosome_length - 1)\n",
        "\n",
        "    middle_to_end_len = chromosome_length - start_to_middle_len\n",
        "\n",
        "    child = []\n",
        "\n",
        "    for i in range(start_to_middle_len):\n",
        "        child.append(first_parent[i])\n",
        "\n",
        "    for i in range(middle_to_end_len):\n",
        "        child.append(second_parent[i + start_to_middle_len])\n",
        "\n",
        "    return child"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {
        "id": "1TBWOyuBT1Dz"
      },
      "outputs": [],
      "source": [
        "def mutation(child):\n",
        "    for i in range(len(child)):\n",
        "        if random.random() < 0.1:\n",
        "            if child[i] == '0':\n",
        "                # print('0->1 at index: ' + str(i))\n",
        "                child[i] = '1'\n",
        "                break\n",
        "            else:\n",
        "                # print('1->0 at index: ' + str(i))\n",
        "                child[i] = '0'\n",
        "                break\n",
        "\n",
        "    return ''.join(child)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {
        "id": "2BEcNIl4aLQn"
      },
      "outputs": [],
      "source": [
        "def generate_new_population(long_list):\n",
        "    new_population = []\n",
        "    for i in range(6):\n",
        "        first_parent = random.choice(long_list)\n",
        "        second_parent = random.choice(long_list)\n",
        "\n",
        "        while first_parent == second_parent:\n",
        "          second_parent = random.choice(long_list)\n",
        "\n",
        "        child = crossover(map[first_parent], map[second_parent])\n",
        "        new_population.append(mutation(child))\n",
        "    return new_population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzJtXJZ_aN7K",
        "outputId": "5f8bfbb5-1785-4069-8928-a5b5909747d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['111010', '111011', '100001', '111110', '110111', '110110']\n",
            "[58, 59, 33, 62, 55, 54]\n",
            "{58: '111010', 59: '111011', 33: '100001', 62: '111110', 55: '110111', 54: '110110'}\n"
          ]
        }
      ],
      "source": [
        "new_population_strings = generate_new_population(long_list)\n",
        "\n",
        "new_population_integers = []\n",
        "\n",
        "for i in range(6):\n",
        "  new_population_integers.append(int(new_population_strings[i], 2))\n",
        "\n",
        "print(new_population_strings)\n",
        "print(new_population_integers)\n",
        "\n",
        "map.clear()\n",
        "\n",
        "for i in range(6):\n",
        "  map[new_population_integers[i]] = new_population_strings[i]\n",
        "\n",
        "print(map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzStchSNgvfw"
      },
      "source": [
        "---\n",
        "\n",
        "# **8. Loop while?... -> just n iterations**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhnCgenXg246",
        "outputId": "f3f09cbb-7635-480c-ee1f-1a846d5069f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "43/43 [==============================] - 2s 7ms/step - loss: 2.0783 - accuracy: 0.3816 - val_loss: 1.8079 - val_accuracy: 0.5489\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.6026 - accuracy: 0.6852 - val_loss: 1.3830 - val_accuracy: 0.7711\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.2043 - accuracy: 0.8270 - val_loss: 1.0338 - val_accuracy: 0.8467\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.8945 - accuracy: 0.8753 - val_loss: 0.7841 - val_accuracy: 0.8778\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.9013 - val_loss: 0.6225 - val_accuracy: 0.8867\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.9161 - val_loss: 0.4996 - val_accuracy: 0.9156\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.9243 - val_loss: 0.4149 - val_accuracy: 0.9200\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3589 - accuracy: 0.9354 - val_loss: 0.3547 - val_accuracy: 0.9156\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3058 - accuracy: 0.9406 - val_loss: 0.3144 - val_accuracy: 0.9200\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2672 - accuracy: 0.9465 - val_loss: 0.2850 - val_accuracy: 0.9311\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2364 - accuracy: 0.9510 - val_loss: 0.2668 - val_accuracy: 0.9289\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2138 - accuracy: 0.9555 - val_loss: 0.2582 - val_accuracy: 0.9244\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1967 - accuracy: 0.9592 - val_loss: 0.2265 - val_accuracy: 0.9444\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.9577 - val_loss: 0.2276 - val_accuracy: 0.9333\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1670 - accuracy: 0.9703 - val_loss: 0.2168 - val_accuracy: 0.9378\n",
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 6ms/step - loss: 2.0438 - accuracy: 0.3860 - val_loss: 1.7691 - val_accuracy: 0.6933\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 1.5569 - accuracy: 0.7699 - val_loss: 1.3465 - val_accuracy: 0.8089\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.1622 - accuracy: 0.8523 - val_loss: 1.0031 - val_accuracy: 0.8689\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.8532 - accuracy: 0.8916 - val_loss: 0.7528 - val_accuracy: 0.8800\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.9109 - val_loss: 0.5703 - val_accuracy: 0.9133\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.9250 - val_loss: 0.4569 - val_accuracy: 0.9178\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3963 - accuracy: 0.9310 - val_loss: 0.3953 - val_accuracy: 0.9089\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.9406 - val_loss: 0.3398 - val_accuracy: 0.9356\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2829 - accuracy: 0.9503 - val_loss: 0.3051 - val_accuracy: 0.9244\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2515 - accuracy: 0.9525 - val_loss: 0.2676 - val_accuracy: 0.9356\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2209 - accuracy: 0.9540 - val_loss: 0.2447 - val_accuracy: 0.9356\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2006 - accuracy: 0.9577 - val_loss: 0.2281 - val_accuracy: 0.9444\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1801 - accuracy: 0.9666 - val_loss: 0.2196 - val_accuracy: 0.9400\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1652 - accuracy: 0.9673 - val_loss: 0.2015 - val_accuracy: 0.9511\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1510 - accuracy: 0.9651 - val_loss: 0.1952 - val_accuracy: 0.9467\n",
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 6ms/step - loss: 2.0613 - accuracy: 0.3385 - val_loss: 1.8652 - val_accuracy: 0.5422\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.7322 - accuracy: 0.6132 - val_loss: 1.5825 - val_accuracy: 0.6422\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.4409 - accuracy: 0.7120 - val_loss: 1.3116 - val_accuracy: 0.7200\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.1768 - accuracy: 0.7780 - val_loss: 1.0689 - val_accuracy: 0.7844\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.9588 - accuracy: 0.8263 - val_loss: 0.8774 - val_accuracy: 0.8178\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.7833 - accuracy: 0.8523 - val_loss: 0.7241 - val_accuracy: 0.8622\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.8812 - val_loss: 0.6207 - val_accuracy: 0.8711\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.9065 - val_loss: 0.5376 - val_accuracy: 0.8933\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.9139 - val_loss: 0.4604 - val_accuracy: 0.9156\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.9272 - val_loss: 0.4092 - val_accuracy: 0.9178\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.9317 - val_loss: 0.3727 - val_accuracy: 0.9222\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3188 - accuracy: 0.9362 - val_loss: 0.3498 - val_accuracy: 0.9156\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2879 - accuracy: 0.9443 - val_loss: 0.3073 - val_accuracy: 0.9333\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2614 - accuracy: 0.9465 - val_loss: 0.2848 - val_accuracy: 0.9356\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2388 - accuracy: 0.9517 - val_loss: 0.2675 - val_accuracy: 0.9356\n",
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 6ms/step - loss: 2.0219 - accuracy: 0.3905 - val_loss: 1.7145 - val_accuracy: 0.6467\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 1.5032 - accuracy: 0.7788 - val_loss: 1.2719 - val_accuracy: 0.8133\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 1.0982 - accuracy: 0.8641 - val_loss: 0.9232 - val_accuracy: 0.8889\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.8028 - accuracy: 0.8946 - val_loss: 0.6981 - val_accuracy: 0.8867\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.9139 - val_loss: 0.5431 - val_accuracy: 0.9178\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.9243 - val_loss: 0.4257 - val_accuracy: 0.9333\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.9317 - val_loss: 0.3543 - val_accuracy: 0.9333\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3101 - accuracy: 0.9465 - val_loss: 0.3138 - val_accuracy: 0.9333\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2653 - accuracy: 0.9517 - val_loss: 0.2768 - val_accuracy: 0.9400\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2317 - accuracy: 0.9547 - val_loss: 0.2493 - val_accuracy: 0.9400\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2050 - accuracy: 0.9621 - val_loss: 0.2322 - val_accuracy: 0.9422\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1843 - accuracy: 0.9621 - val_loss: 0.2128 - val_accuracy: 0.9511\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1674 - accuracy: 0.9636 - val_loss: 0.2093 - val_accuracy: 0.9489\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1549 - accuracy: 0.9718 - val_loss: 0.1900 - val_accuracy: 0.9511\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9710 - val_loss: 0.1782 - val_accuracy: 0.9622\n",
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 6ms/step - loss: 2.0617 - accuracy: 0.3504 - val_loss: 1.7579 - val_accuracy: 0.6356\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 1.5550 - accuracy: 0.7201 - val_loss: 1.3172 - val_accuracy: 0.7711\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.1556 - accuracy: 0.8092 - val_loss: 0.9744 - val_accuracy: 0.8556\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.8497 - accuracy: 0.8782 - val_loss: 0.7245 - val_accuracy: 0.8978\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.8990 - val_loss: 0.5703 - val_accuracy: 0.9000\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.9176 - val_loss: 0.4578 - val_accuracy: 0.9222\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.9265 - val_loss: 0.3867 - val_accuracy: 0.9244\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3419 - accuracy: 0.9354 - val_loss: 0.3327 - val_accuracy: 0.9267\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2914 - accuracy: 0.9465 - val_loss: 0.2972 - val_accuracy: 0.9378\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2563 - accuracy: 0.9532 - val_loss: 0.2629 - val_accuracy: 0.9489\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2271 - accuracy: 0.9510 - val_loss: 0.2405 - val_accuracy: 0.9444\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2022 - accuracy: 0.9592 - val_loss: 0.2275 - val_accuracy: 0.9444\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1846 - accuracy: 0.9607 - val_loss: 0.2089 - val_accuracy: 0.9533\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1690 - accuracy: 0.9644 - val_loss: 0.1959 - val_accuracy: 0.9578\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1534 - accuracy: 0.9673 - val_loss: 0.1877 - val_accuracy: 0.9556\n",
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 7ms/step - loss: 2.0954 - accuracy: 0.3022 - val_loss: 1.8174 - val_accuracy: 0.6289\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.5970 - accuracy: 0.7313 - val_loss: 1.3877 - val_accuracy: 0.8111\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.2096 - accuracy: 0.8448 - val_loss: 1.0580 - val_accuracy: 0.8467\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.9061 - accuracy: 0.8812 - val_loss: 0.7948 - val_accuracy: 0.8644\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.6815 - accuracy: 0.8946 - val_loss: 0.6121 - val_accuracy: 0.9022\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.9183 - val_loss: 0.4898 - val_accuracy: 0.9178\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.9317 - val_loss: 0.4078 - val_accuracy: 0.9200\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.9414 - val_loss: 0.3562 - val_accuracy: 0.9200\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2990 - accuracy: 0.9451 - val_loss: 0.3194 - val_accuracy: 0.9267\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.9488 - val_loss: 0.2835 - val_accuracy: 0.9378\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2339 - accuracy: 0.9547 - val_loss: 0.2618 - val_accuracy: 0.9333\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9562 - val_loss: 0.2395 - val_accuracy: 0.9378\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1899 - accuracy: 0.9629 - val_loss: 0.2223 - val_accuracy: 0.9400\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1730 - accuracy: 0.9651 - val_loss: 0.2212 - val_accuracy: 0.9356\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.1603 - accuracy: 0.9681 - val_loss: 0.2083 - val_accuracy: 0.9378\n",
            "loop iteration 1:\n",
            "------------------------------------\n",
            "models sizes: [58, 59, 33, 62, 55, 54]\n",
            "\n",
            "model 1 loss: 9.349200800061226\n",
            "model 2 loss: 8.924047395586967\n",
            "model 3 loss: 11.682836785912514\n",
            "model 4 loss: 8.533689633011818\n",
            "model 5 loss: 9.002181828022003\n",
            "model 6 loss: 9.320043697953224\n",
            "average models loss: 9.468666690091291\n",
            "\n",
            "new population strings:\n",
            "['101010', '110110', '110010', '111110', '111100', '110110']\n",
            "new population integeers:\n",
            "[42, 54, 50, 62, 60, 54]\n",
            "map:\n",
            "{42: '101010', 54: '110110', 50: '110010', 62: '111110', 60: '111100'}\n",
            "------------------------------------\n",
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 7ms/step - loss: 2.0556 - accuracy: 0.3385 - val_loss: 1.8200 - val_accuracy: 0.6178\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.6416 - accuracy: 0.7313 - val_loss: 1.4690 - val_accuracy: 0.7867\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.3077 - accuracy: 0.8367 - val_loss: 1.1516 - val_accuracy: 0.8533\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.0170 - accuracy: 0.8827 - val_loss: 0.8914 - val_accuracy: 0.9067\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.7894 - accuracy: 0.8976 - val_loss: 0.7099 - val_accuracy: 0.8911\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.6246 - accuracy: 0.9094 - val_loss: 0.5799 - val_accuracy: 0.8978\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.9139 - val_loss: 0.4730 - val_accuracy: 0.9156\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.9295 - val_loss: 0.4065 - val_accuracy: 0.9156\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 0.9369 - val_loss: 0.3608 - val_accuracy: 0.9222\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3104 - accuracy: 0.9376 - val_loss: 0.3223 - val_accuracy: 0.9311\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.2729 - accuracy: 0.9488 - val_loss: 0.2925 - val_accuracy: 0.9422\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2419 - accuracy: 0.9562 - val_loss: 0.2637 - val_accuracy: 0.9444\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2207 - accuracy: 0.9555 - val_loss: 0.2434 - val_accuracy: 0.9467\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 5ms/step - loss: 0.2033 - accuracy: 0.9592 - val_loss: 0.2328 - val_accuracy: 0.9333\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.1878 - accuracy: 0.9592 - val_loss: 0.2203 - val_accuracy: 0.9444\n",
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 8ms/step - loss: 1.9994 - accuracy: 0.4417 - val_loss: 1.6780 - val_accuracy: 0.6533\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 1.4719 - accuracy: 0.7647 - val_loss: 1.2427 - val_accuracy: 0.8400\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.0812 - accuracy: 0.8500 - val_loss: 0.9057 - val_accuracy: 0.8689\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.7940 - accuracy: 0.8834 - val_loss: 0.6810 - val_accuracy: 0.9044\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.9102 - val_loss: 0.5370 - val_accuracy: 0.9133\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.9235 - val_loss: 0.4367 - val_accuracy: 0.9178\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3827 - accuracy: 0.9347 - val_loss: 0.3697 - val_accuracy: 0.9133\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3204 - accuracy: 0.9414 - val_loss: 0.3313 - val_accuracy: 0.9178\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2789 - accuracy: 0.9465 - val_loss: 0.2875 - val_accuracy: 0.9356\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.9495 - val_loss: 0.2641 - val_accuracy: 0.9356\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2199 - accuracy: 0.9555 - val_loss: 0.2374 - val_accuracy: 0.9422\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1960 - accuracy: 0.9599 - val_loss: 0.2278 - val_accuracy: 0.9400\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1808 - accuracy: 0.9636 - val_loss: 0.2139 - val_accuracy: 0.9400\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.1678 - accuracy: 0.9666 - val_loss: 0.1986 - val_accuracy: 0.9422\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.9673 - val_loss: 0.1898 - val_accuracy: 0.9489\n",
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 6ms/step - loss: 1.9897 - accuracy: 0.3653 - val_loss: 1.6834 - val_accuracy: 0.6489\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.4779 - accuracy: 0.7587 - val_loss: 1.2566 - val_accuracy: 0.8289\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.0988 - accuracy: 0.8508 - val_loss: 0.9374 - val_accuracy: 0.8733\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.8182 - accuracy: 0.8894 - val_loss: 0.7084 - val_accuracy: 0.8711\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.9035 - val_loss: 0.5604 - val_accuracy: 0.9089\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.9243 - val_loss: 0.4475 - val_accuracy: 0.9156\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3943 - accuracy: 0.9272 - val_loss: 0.3792 - val_accuracy: 0.9178\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.9369 - val_loss: 0.3278 - val_accuracy: 0.9289\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2864 - accuracy: 0.9436 - val_loss: 0.2964 - val_accuracy: 0.9244\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.9488 - val_loss: 0.2705 - val_accuracy: 0.9311\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2262 - accuracy: 0.9547 - val_loss: 0.2480 - val_accuracy: 0.9356\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2017 - accuracy: 0.9532 - val_loss: 0.2221 - val_accuracy: 0.9511\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1846 - accuracy: 0.9607 - val_loss: 0.2102 - val_accuracy: 0.9511\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.1701 - accuracy: 0.9659 - val_loss: 0.1991 - val_accuracy: 0.9511\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.1575 - accuracy: 0.9666 - val_loss: 0.1904 - val_accuracy: 0.9444\n",
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 7ms/step - loss: 2.0097 - accuracy: 0.3756 - val_loss: 1.6851 - val_accuracy: 0.7156\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 1.4716 - accuracy: 0.7773 - val_loss: 1.2450 - val_accuracy: 0.8511\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.0689 - accuracy: 0.8723 - val_loss: 0.8985 - val_accuracy: 0.8733\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.7753 - accuracy: 0.8938 - val_loss: 0.6687 - val_accuracy: 0.9111\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.9198 - val_loss: 0.5166 - val_accuracy: 0.9222\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.9339 - val_loss: 0.4247 - val_accuracy: 0.9244\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.3662 - accuracy: 0.9406 - val_loss: 0.3547 - val_accuracy: 0.9333\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3042 - accuracy: 0.9451 - val_loss: 0.3126 - val_accuracy: 0.9333\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2610 - accuracy: 0.9517 - val_loss: 0.2709 - val_accuracy: 0.9444\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2305 - accuracy: 0.9547 - val_loss: 0.2481 - val_accuracy: 0.9333\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2049 - accuracy: 0.9584 - val_loss: 0.2231 - val_accuracy: 0.9467\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1862 - accuracy: 0.9614 - val_loss: 0.2066 - val_accuracy: 0.9489\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1697 - accuracy: 0.9651 - val_loss: 0.1952 - val_accuracy: 0.9422\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1567 - accuracy: 0.9636 - val_loss: 0.1886 - val_accuracy: 0.9489\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9725 - val_loss: 0.1820 - val_accuracy: 0.9489\n",
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 7ms/step - loss: 2.0863 - accuracy: 0.3326 - val_loss: 1.7885 - val_accuracy: 0.6889\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.5696 - accuracy: 0.7498 - val_loss: 1.3333 - val_accuracy: 0.8311\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.1579 - accuracy: 0.8545 - val_loss: 0.9853 - val_accuracy: 0.8733\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.8401 - accuracy: 0.8909 - val_loss: 0.7292 - val_accuracy: 0.9000\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.6176 - accuracy: 0.9131 - val_loss: 0.5514 - val_accuracy: 0.9267\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.9265 - val_loss: 0.4586 - val_accuracy: 0.9089\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3781 - accuracy: 0.9347 - val_loss: 0.3870 - val_accuracy: 0.9244\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3148 - accuracy: 0.9495 - val_loss: 0.3251 - val_accuracy: 0.9289\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2685 - accuracy: 0.9517 - val_loss: 0.2972 - val_accuracy: 0.9333\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.2350 - accuracy: 0.9577 - val_loss: 0.2605 - val_accuracy: 0.9356\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2077 - accuracy: 0.9599 - val_loss: 0.2432 - val_accuracy: 0.9311\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1865 - accuracy: 0.9621 - val_loss: 0.2252 - val_accuracy: 0.9333\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1680 - accuracy: 0.9673 - val_loss: 0.2112 - val_accuracy: 0.9378\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.9673 - val_loss: 0.2053 - val_accuracy: 0.9356\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9703 - val_loss: 0.1978 - val_accuracy: 0.9444\n",
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 6ms/step - loss: 2.0152 - accuracy: 0.4276 - val_loss: 1.7446 - val_accuracy: 0.6733\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.5405 - accuracy: 0.7676 - val_loss: 1.3166 - val_accuracy: 0.8400\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.1522 - accuracy: 0.8359 - val_loss: 0.9908 - val_accuracy: 0.8622\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.8615 - accuracy: 0.8760 - val_loss: 0.7828 - val_accuracy: 0.8467\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.8924 - val_loss: 0.5984 - val_accuracy: 0.8911\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.9072 - val_loss: 0.4900 - val_accuracy: 0.8978\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.9302 - val_loss: 0.4072 - val_accuracy: 0.9133\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3444 - accuracy: 0.9347 - val_loss: 0.3488 - val_accuracy: 0.9311\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2908 - accuracy: 0.9488 - val_loss: 0.3169 - val_accuracy: 0.9222\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2555 - accuracy: 0.9510 - val_loss: 0.2826 - val_accuracy: 0.9289\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2266 - accuracy: 0.9547 - val_loss: 0.2684 - val_accuracy: 0.9178\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2034 - accuracy: 0.9584 - val_loss: 0.2413 - val_accuracy: 0.9444\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1871 - accuracy: 0.9607 - val_loss: 0.2269 - val_accuracy: 0.9467\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1698 - accuracy: 0.9651 - val_loss: 0.2125 - val_accuracy: 0.9467\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1575 - accuracy: 0.9651 - val_loss: 0.2036 - val_accuracy: 0.9467\n",
            "loop iteration 2:\n",
            "------------------------------------\n",
            "models sizes: [42, 54, 50, 62, 60, 54]\n",
            "\n",
            "model 1 loss: 10.15880000591278\n",
            "model 2 loss: 8.566550567746162\n",
            "model 3 loss: 8.693083062767982\n",
            "model 4 loss: 8.377921253442764\n",
            "model 5 loss: 8.799159094691277\n",
            "model 6 loss: 8.989667773246765\n",
            "average models loss: 8.930863626301289\n",
            "\n",
            "new population strings:\n",
            "['110100', '010110', '111010', '110110', '110110', '100110']\n",
            "new population integeers:\n",
            "[52, 22, 58, 54, 54, 38]\n",
            "map:\n",
            "{52: '110100', 22: '010110', 58: '111010', 54: '110110', 38: '100110'}\n",
            "------------------------------------\n",
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 6ms/step - loss: 2.1483 - accuracy: 0.2606 - val_loss: 1.9038 - val_accuracy: 0.5400\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.7218 - accuracy: 0.7075 - val_loss: 1.4856 - val_accuracy: 0.7978\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.3145 - accuracy: 0.8285 - val_loss: 1.1245 - val_accuracy: 0.8733\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.9907 - accuracy: 0.8842 - val_loss: 0.8477 - val_accuracy: 0.8822\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.7502 - accuracy: 0.9027 - val_loss: 0.6557 - val_accuracy: 0.9022\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.9146 - val_loss: 0.5392 - val_accuracy: 0.8978\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.9220 - val_loss: 0.4412 - val_accuracy: 0.9178\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.9287 - val_loss: 0.3797 - val_accuracy: 0.9133\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3274 - accuracy: 0.9317 - val_loss: 0.3343 - val_accuracy: 0.9267\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2861 - accuracy: 0.9399 - val_loss: 0.3089 - val_accuracy: 0.9222\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2528 - accuracy: 0.9436 - val_loss: 0.2739 - val_accuracy: 0.9244\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2259 - accuracy: 0.9532 - val_loss: 0.2628 - val_accuracy: 0.9267\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2053 - accuracy: 0.9540 - val_loss: 0.2396 - val_accuracy: 0.9378\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1889 - accuracy: 0.9569 - val_loss: 0.2272 - val_accuracy: 0.9467\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9584 - val_loss: 0.2232 - val_accuracy: 0.9356\n",
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 6ms/step - loss: 2.1766 - accuracy: 0.1878 - val_loss: 2.0086 - val_accuracy: 0.4089\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 1.8913 - accuracy: 0.5152 - val_loss: 1.7419 - val_accuracy: 0.6489\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.6255 - accuracy: 0.6875 - val_loss: 1.4857 - val_accuracy: 0.6844\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.3781 - accuracy: 0.7661 - val_loss: 1.2486 - val_accuracy: 0.7289\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 1.1497 - accuracy: 0.7825 - val_loss: 1.0409 - val_accuracy: 0.8133\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.9603 - accuracy: 0.8382 - val_loss: 0.8655 - val_accuracy: 0.8511\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.8046 - accuracy: 0.8582 - val_loss: 0.7406 - val_accuracy: 0.8644\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.8820 - val_loss: 0.6311 - val_accuracy: 0.8867\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.8938 - val_loss: 0.5429 - val_accuracy: 0.9000\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.9087 - val_loss: 0.4750 - val_accuracy: 0.9111\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.9176 - val_loss: 0.4276 - val_accuracy: 0.9200\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4002 - accuracy: 0.9243 - val_loss: 0.3833 - val_accuracy: 0.9267\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.9235 - val_loss: 0.3472 - val_accuracy: 0.9333\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3247 - accuracy: 0.9332 - val_loss: 0.3205 - val_accuracy: 0.9400\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2974 - accuracy: 0.9399 - val_loss: 0.2995 - val_accuracy: 0.9311\n",
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 6ms/step - loss: 2.0298 - accuracy: 0.3489 - val_loss: 1.7288 - val_accuracy: 0.5956\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.4988 - accuracy: 0.7298 - val_loss: 1.2732 - val_accuracy: 0.8222\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.0805 - accuracy: 0.8471 - val_loss: 0.9243 - val_accuracy: 0.8556\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.7874 - accuracy: 0.8834 - val_loss: 0.6809 - val_accuracy: 0.8889\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.9087 - val_loss: 0.5263 - val_accuracy: 0.8978\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.9213 - val_loss: 0.4354 - val_accuracy: 0.9044\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3708 - accuracy: 0.9302 - val_loss: 0.3683 - val_accuracy: 0.9244\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3111 - accuracy: 0.9369 - val_loss: 0.3282 - val_accuracy: 0.9289\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2701 - accuracy: 0.9503 - val_loss: 0.2912 - val_accuracy: 0.9333\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2353 - accuracy: 0.9532 - val_loss: 0.2670 - val_accuracy: 0.9311\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9592 - val_loss: 0.2381 - val_accuracy: 0.9400\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1889 - accuracy: 0.9629 - val_loss: 0.2325 - val_accuracy: 0.9400\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1721 - accuracy: 0.9614 - val_loss: 0.2203 - val_accuracy: 0.9467\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1579 - accuracy: 0.9688 - val_loss: 0.2092 - val_accuracy: 0.9444\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9740 - val_loss: 0.1917 - val_accuracy: 0.9467\n",
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 6ms/step - loss: 2.0458 - accuracy: 0.3771 - val_loss: 1.7413 - val_accuracy: 0.6356\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.5616 - accuracy: 0.7090 - val_loss: 1.3359 - val_accuracy: 0.7733\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.1789 - accuracy: 0.8263 - val_loss: 0.9923 - val_accuracy: 0.8378\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.8744 - accuracy: 0.8716 - val_loss: 0.7442 - val_accuracy: 0.8911\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.8998 - val_loss: 0.5801 - val_accuracy: 0.8844\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.9139 - val_loss: 0.4644 - val_accuracy: 0.9133\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.9220 - val_loss: 0.3960 - val_accuracy: 0.9333\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3543 - accuracy: 0.9310 - val_loss: 0.3453 - val_accuracy: 0.9267\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3051 - accuracy: 0.9391 - val_loss: 0.3010 - val_accuracy: 0.9400\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2655 - accuracy: 0.9436 - val_loss: 0.2878 - val_accuracy: 0.9333\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2350 - accuracy: 0.9473 - val_loss: 0.2489 - val_accuracy: 0.9489\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2129 - accuracy: 0.9510 - val_loss: 0.2331 - val_accuracy: 0.9467\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1928 - accuracy: 0.9607 - val_loss: 0.2270 - val_accuracy: 0.9422\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1783 - accuracy: 0.9644 - val_loss: 0.2177 - val_accuracy: 0.9422\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1659 - accuracy: 0.9607 - val_loss: 0.1953 - val_accuracy: 0.9533\n",
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 6ms/step - loss: 1.9516 - accuracy: 0.4120 - val_loss: 1.6931 - val_accuracy: 0.6489\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.5017 - accuracy: 0.7120 - val_loss: 1.2844 - val_accuracy: 0.8067\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.1215 - accuracy: 0.8515 - val_loss: 0.9471 - val_accuracy: 0.8822\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.8239 - accuracy: 0.8916 - val_loss: 0.7094 - val_accuracy: 0.8911\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.6134 - accuracy: 0.9065 - val_loss: 0.5423 - val_accuracy: 0.9156\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.9228 - val_loss: 0.4403 - val_accuracy: 0.9133\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.9347 - val_loss: 0.3763 - val_accuracy: 0.9156\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3209 - accuracy: 0.9399 - val_loss: 0.3256 - val_accuracy: 0.9267\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.9473 - val_loss: 0.2862 - val_accuracy: 0.9311\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2412 - accuracy: 0.9540 - val_loss: 0.2649 - val_accuracy: 0.9356\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2132 - accuracy: 0.9577 - val_loss: 0.2433 - val_accuracy: 0.9356\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1903 - accuracy: 0.9621 - val_loss: 0.2188 - val_accuracy: 0.9422\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1719 - accuracy: 0.9696 - val_loss: 0.2055 - val_accuracy: 0.9444\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1576 - accuracy: 0.9651 - val_loss: 0.1924 - val_accuracy: 0.9511\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.9703 - val_loss: 0.1790 - val_accuracy: 0.9556\n",
            "Epoch 1/15\n",
            "43/43 [==============================] - 1s 7ms/step - loss: 2.1138 - accuracy: 0.3244 - val_loss: 1.8774 - val_accuracy: 0.5467\n",
            "Epoch 2/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.6927 - accuracy: 0.6377 - val_loss: 1.4545 - val_accuracy: 0.7600\n",
            "Epoch 3/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.3044 - accuracy: 0.7832 - val_loss: 1.1423 - val_accuracy: 0.8178\n",
            "Epoch 4/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 1.0139 - accuracy: 0.8671 - val_loss: 0.8786 - val_accuracy: 0.8822\n",
            "Epoch 5/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.7918 - accuracy: 0.8797 - val_loss: 0.6980 - val_accuracy: 0.8911\n",
            "Epoch 6/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.9020 - val_loss: 0.5695 - val_accuracy: 0.8933\n",
            "Epoch 7/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.9079 - val_loss: 0.4772 - val_accuracy: 0.9178\n",
            "Epoch 8/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.9243 - val_loss: 0.4070 - val_accuracy: 0.9200\n",
            "Epoch 9/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.9324 - val_loss: 0.3633 - val_accuracy: 0.9133\n",
            "Epoch 10/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.9354 - val_loss: 0.3261 - val_accuracy: 0.9178\n",
            "Epoch 11/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2813 - accuracy: 0.9399 - val_loss: 0.2958 - val_accuracy: 0.9311\n",
            "Epoch 12/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2530 - accuracy: 0.9480 - val_loss: 0.2756 - val_accuracy: 0.9378\n",
            "Epoch 13/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.2303 - accuracy: 0.9495 - val_loss: 0.2536 - val_accuracy: 0.9400\n",
            "Epoch 14/15\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 0.2100 - accuracy: 0.9547 - val_loss: 0.2392 - val_accuracy: 0.9422\n",
            "Epoch 15/15\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.1943 - accuracy: 0.9599 - val_loss: 0.2244 - val_accuracy: 0.9467\n",
            "loop iteration 3:\n",
            "------------------------------------\n",
            "models sizes: [52, 22, 58, 54, 54, 38]\n",
            "\n",
            "model 1 loss: 10.030811458826065\n",
            "model 2 loss: 13.598149985074997\n",
            "model 3 loss: 8.498658433556557\n",
            "model 4 loss: 9.17132356762886\n",
            "model 5 loss: 8.587136298418045\n",
            "model 6 loss: 10.327760562300682\n",
            "average models loss: 10.035640050967535\n",
            "\n",
            "new population strings:\n",
            "['110101', '011010', '111110', '110010', '110110', '110100']\n",
            "new population integeers:\n",
            "[53, 26, 62, 50, 54, 52]\n",
            "map:\n",
            "{53: '110101', 26: '011010', 62: '111110', 50: '110010', 54: '110110', 52: '110100'}\n",
            "------------------------------------\n"
          ]
        }
      ],
      "source": [
        "n_iterations = 0\n",
        "\n",
        "new_population_integers_loop = new_population_integers\n",
        "\n",
        "while n_iterations < 3:\n",
        "  # MODEL 1\n",
        "  model_1_loop = models.Sequential()\n",
        "\n",
        "  if new_population_integers_loop[0] != 0:\n",
        "    model_1_loop.add(layers.Dense(new_population_integers_loop[0], activation='relu', name='hidden', input_dim=64))\n",
        "    model_1_loop.add(layers.Dense(10, activation='softmax', name='output'))\n",
        "  else:\n",
        "    model_1_loop.add(layers.Dense(10, activation='softmax', name='output', input_dim=64))\n",
        "\n",
        "  model_1_loop.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  # MODEL 2\n",
        "  model_2_loop = models.Sequential()\n",
        "\n",
        "  if new_population_integers_loop[1] != 0:\n",
        "    model_2_loop.add(layers.Dense(new_population_integers_loop[1], activation='relu', name='hidden', input_dim=64))\n",
        "    model_2_loop.add(layers.Dense(10, activation='softmax', name='output'))\n",
        "  else:\n",
        "    model_2_loop.add(layers.Dense(10, activation='softmax', name='output', input_dim=64))\n",
        "\n",
        "  model_2_loop.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  # MODEL 3\n",
        "  model_3_loop = models.Sequential()\n",
        "\n",
        "  if new_population_integers_loop[2] != 0:\n",
        "    model_3_loop.add(layers.Dense(new_population_integers_loop[2], activation='relu', name='hidden', input_dim=64))\n",
        "    model_3_loop.add(layers.Dense(10, activation='softmax', name='output'))\n",
        "  else:\n",
        "    model_3_loop.add(layers.Dense(10, activation='softmax', name='output', input_dim=64))\n",
        "\n",
        "  model_3_loop.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  # MODEL 4\n",
        "  model_4_loop = models.Sequential()\n",
        "\n",
        "  if new_population_integers_loop[3] != 0:\n",
        "    model_4_loop.add(layers.Dense(new_population_integers_loop[3], activation='relu', name='hidden', input_dim=64))\n",
        "    model_4_loop.add(layers.Dense(10, activation='softmax', name='output'))\n",
        "  else:\n",
        "    model_4_loop.add(layers.Dense(10, activation='softmax', name='output', input_dim=64))\n",
        "\n",
        "  model_4_loop.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  # MODEL 5\n",
        "  model_5_loop = models.Sequential()\n",
        "\n",
        "  if new_population_integers_loop[4] != 0:\n",
        "    model_5_loop.add(layers.Dense(new_population_integers_loop[4], activation='relu', name='hidden', input_dim=64))\n",
        "    model_5_loop.add(layers.Dense(10, activation='softmax', name='output'))\n",
        "  else:\n",
        "    model_5_loop.add(layers.Dense(10, activation='softmax', name='output', input_dim=64))\n",
        "\n",
        "  model_5_loop.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  # MODEL 6\n",
        "  model_6_loop = models.Sequential()\n",
        "\n",
        "  if new_population_integers_loop[5] != 0:\n",
        "    model_6_loop.add(layers.Dense(new_population_integers_loop[5], activation='relu', name='hidden', input_dim=64))\n",
        "    model_6_loop.add(layers.Dense(10, activation='softmax', name='output'))\n",
        "  else:\n",
        "    model_6_loop.add(layers.Dense(10, activation='softmax', name='output', input_dim=64))\n",
        "\n",
        "  model_6_loop.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  # FITTING ALL MODELS\n",
        "  fit_1_loop = model_1_loop.fit(input_train, targets_train, epochs=n_epochs, validation_data=(input_test, targets_test))\n",
        "  fit_2_loop = model_2_loop.fit(input_train, targets_train, epochs=n_epochs, validation_data=(input_test, targets_test))\n",
        "  fit_3_loop = model_3_loop.fit(input_train, targets_train, epochs=n_epochs, validation_data=(input_test, targets_test))\n",
        "  fit_4_loop = model_4_loop.fit(input_train, targets_train, epochs=n_epochs, validation_data=(input_test, targets_test))\n",
        "  fit_5_loop = model_5_loop.fit(input_train, targets_train, epochs=n_epochs, validation_data=(input_test, targets_test))\n",
        "  fit_6_loop = model_6_loop.fit(input_train, targets_train, epochs=n_epochs, validation_data=(input_test, targets_test))\n",
        "\n",
        "  # CALCULATING FITNESS FOR EVERY MODEL\n",
        "  fitness_list_loop = fitness_function(fit_1_loop, fit_2_loop, fit_3_loop, fit_4_loop, fit_5_loop, fit_6_loop)\n",
        "\n",
        "  # PRINTING LOSS SUM OF EVERY MODEL\n",
        "  model_1_loss = fitness_list_loop[0]\n",
        "  model_2_loss = fitness_list_loop[1]\n",
        "  model_3_loss = fitness_list_loop[2]\n",
        "  model_4_loss = fitness_list_loop[3]\n",
        "  model_5_loss = fitness_list_loop[4]\n",
        "  model_6_loss = fitness_list_loop[5]\n",
        "\n",
        "  print(\"loop iteration \" + str(n_iterations + 1) + \":\")\n",
        "  print(\"------------------------------------\")\n",
        "  print(\"models sizes: \" + str(new_population_integers_loop) + '\\n')\n",
        "  print(\"model 1 loss: \" + str(model_1_loss))\n",
        "  print(\"model 2 loss: \" + str(model_2_loss))\n",
        "  print(\"model 3 loss: \" + str(model_3_loss))\n",
        "  print(\"model 4 loss: \" + str(model_4_loss))\n",
        "  print(\"model 5 loss: \" + str(model_5_loss))\n",
        "  print(\"model 6 loss: \" + str(model_6_loss))\n",
        "\n",
        "  # CALCULATING AVERAGE MODELS LOSS\n",
        "  average = (model_1_loss + model_2_loss + model_3_loss + model_4_loss + model_5_loss + model_6_loss) / 6.0\n",
        "  print(\"average models loss: \" + str(average))\n",
        "\n",
        "  print()\n",
        "\n",
        "  # FITNESS LIST NORMALIZATION\n",
        "  norm_loop = [float(i)/max(fitness_list_loop) for i in fitness_list_loop]\n",
        "  norm_loop = [1 - i for i in norm_loop]\n",
        "\n",
        "  # PROBABILITIES LIST\n",
        "  probabilities_list_loop = calculate_probability_of_occurrence(norm_loop)\n",
        "  \n",
        "  # WE WILL RANDOMLY TAKE PARENTS FROM THIS LIST\n",
        "  long_list_loop = generate_list_of_probabilities(probabilities_list_loop, new_population_integers_loop)\n",
        "\n",
        "  # GENERATING NEW POPULATION\n",
        "  new_population_strings_loop = generate_new_population(long_list_loop)\n",
        "  new_population_integers_loop = []\n",
        "\n",
        "  for i in range(6):\n",
        "    new_population_integers_loop.append(int(new_population_strings_loop[i], 2))\n",
        "\n",
        "  print(\"new population strings:\")\n",
        "  print(new_population_strings_loop)\n",
        "\n",
        "  print(\"new population integeers:\")\n",
        "  print(new_population_integers_loop)\n",
        "\n",
        "  map.clear()\n",
        "\n",
        "  for i in range(6):\n",
        "    map[new_population_integers_loop[i]] = new_population_strings_loop[i]\n",
        "\n",
        "  print(\"map:\")\n",
        "  print(map)\n",
        "\n",
        "  print(\"------------------------------------\")\n",
        "\n",
        "  n_iterations += 1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Zhdanovich_Genetic3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}